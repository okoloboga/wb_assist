# GPT интеграция в Telegram‑бот WB Assist — спецификация и пошаговая инструкция

Документ описывает цели, архитектуру, требования и конкретные шаги интеграции GPT в существующий Telegram‑бот на aiogram v3 (папка `bot/`). Сценарий ориентирован на минимальные правки, учитывает текущую структуру проекта и существующие middleware/конфиг.

## 1) Цели и сценарии
- Ответы на вопросы пользователей непосредственно из Telegram (команда `/gpt`).
- Генерация текстов: ответы на отзывы, шаблоны уведомлений, описания.
- Объяснение аналитики и данных из WB (суммирование, интерпретация).
- Помощь в формировании запросов к API (подсказки, черновики).

## 2) Текущая архитектура бота (важно для интеграции)
- Вход: `bot/__main__.py` (aiogram v3, `Bot`, `Dispatcher`).
- Маршрутизация: отдельные `handlers/*` (каждый содержит `router = Router()`, далее `dp.include_router(...)`).
- Middleware: `middleware/error_handler.py` (логирование, rate‑limit, обработка ошибок), `middleware/api_key_check.py` (проверка WB API ключа).
- Конфиг: `core/config.py` уже содержит поля OpenAI: `openai_api_key`, `openai_base_url`, `openai_model`, `openai_temperature`, `openai_max_tokens`, `openai_timeout`, `openai_system_prompt`.
- ENV пример: `env_example.txt` уже включает блок "OpenAI (LLM)".

## 3) Архитектура GPT‑интеграции
- `GPTClient` — унифицированная обертка над LLM‑провайдером (по умолчанию OpenAI), async.
- `ConversationManager` — хранение контекста диалога (история последних N сообщений, TTL; начнем с in‑memory на FSM/Dispatcher, опционально Redis).
- `MessageFormatter` — экранирование Markdown/HTML, разбиение на части до лимита Telegram (`4096` символов).
- `RateLimiter` — базовый лимит уже есть (`RateLimitMiddleware`), добавить мягкий лимит на GPT.
- Интеграция: новый роутер `handlers/gpt.py` с `/gpt` (включение режима) и `/exit` (выход), обработка свободного текста в состоянии диалога.

## 4) Подготовка окружения
- Заполните `.env` ключами из `env_example.txt` (минимум `OPENAI_API_KEY`).
- Обновите зависимости `bot/requirements.txt`:
  - Вариант A (официальный SDK): `openai>=1.12.0`.
  - Вариант B (универсальный HTTP‑клиент): `httpx>=0.24` (если не хотите тянуть SDK).
- После обновления зависимостей — `pip install -r bot/requirements.txt`.

## 5) Изменяемые/новые файлы
- `bot/api/gpt_client.py` — реализация клиента GPT (Async, таймауты, model/temperature/max_tokens).
- `bot/core/states.py` — добавить `GPTDialogStates`.
- `bot/utils/formatters.py` — добавить `escape_markdown_v2` и `split_telegram_message`.
- `bot/handlers/gpt.py` — роутер `/gpt`, диалог, `/exit`.
- `bot/__main__.py` — инициализация `GPTClient`, регистрация `gpt_router`, (опционально) диспетчерское хранилище.

## 6) Пошаговая реализация (конкретно под ваш проект)
## Этапы Разработки — подключение GPT

- Этап 1: Подготовка окружения и зависимостей
  - Основные задачи: добавить `openai>=1.12.0` (или `httpx`) в `bot/requirements.txt`, создать `.env`, заполнить `OPENAI_API_KEY`.
  - Артефакты: обновлённый `requirements.txt`, рабочий `.env`.
  - Критерий готовности: зависимости устанавливаются (`pip install -r bot/requirements.txt`), ключ загружается.

- Этап 2: Конфигурация OpenAI в `bot/core/config.py` и `env_example.txt`
  - Основные задачи: убедиться, что поля `openai_*` загружаются из ENV; дополнить `env_example.txt` при необходимости.
  - Артефакты: актуальный `config.py`, обновлённый `env_example.txt`.
  - Критерий готовности: `config.openai_api_key` и остальные параметры доступны при старте.

- Этап 3: Реализация GPT‑клиента (`bot/api/gpt_client.py`)
  - Основные задачи: написать `GPTClient` (AsyncOpenAI + HTTP фолбэк), таймауты, `system_prompt`, `temperature`, `max_tokens`.
  - Артефакты: файл `bot/api/gpt_client.py` с методом `chat(messages)`.
  - Критерий готовности: первый успешный вызов LLM в dev‑окружении (мок/реальный).

- Этап 4: FSM‑состояния диалога (`GPTDialogStates`)
  - Основные задачи: добавить `GPTDialogStates.active` в `bot/core/states.py`.
  - Артефакты: обновлённый `states.py`.
  - Критерий готовности: состояние устанавливается/очищается в хендлерах.

- Этап 5: Форматтеры текста (MarkdownV2, разбиение >4096)
  - Основные задачи: добавить функции `escape_markdown_v2` и `split_telegram_message` в `bot/utils/formatters.py`.
  - Артефакты: обновлённый `formatters.py`.
  - Критерий готовности: длинные ответы отправляются без ошибок форматирования.

- Этап 6: Хендлеры чата (`/gpt`, диалог, `/exit`) и клавиатуры
  - Основные задачи: создать `bot/handlers/gpt.py`, реализовать `/gpt`, свободный ввод в `GPTDialogStates.active`, `/exit`; при необходимости — кнопки.
  - Артефакты: новый роутер `handlers/gpt.py`, (опционально) обновлённые клавиатуры.
  - Критерий готовности: диалог запускается и завершается, ответы приходят.

- Этап 7: Регистрация клиента и роутера в `bot/__main__.py`
  - Основные задачи: инициализировать `GPTClient` из `config`, положить в `dp["gpt_client"]`, `dp.include_router(gpt_router)`.
  - Артефакты: правки `__main__.py`.
  - Критерий готовности: бот стартует, `/gpt` видна и работает.

- Этап 8: Ограничение доступа и rate‑limit
  - Основные задачи: настроить исключения для `/gpt` в `APIKeyCheckMiddleware` (если требуется доступ всем), добавить мягкий per‑user лимит.
  - Артефакты: правки `middleware/api_key_check.py` (и/или отдельный лимитер).
  - Критерий готовности: ограничения применяются, нет флуда/спама.

- Этап 9: Логи и метрики для GPT‑диалога
  - Основные задачи: расширить `LoggingMiddleware` для логирования входа/выхода, размера сообщений, времени ответа, ошибок.
  - Артефакты: правки `middleware/error_handler.py`.
  - Критерий готовности: в логах видна статистика по GPT‑диалогу.

- Этап 10: Тесты (unit и интеграционные для FSM и хендлеров)
  - Основные задачи: юнит‑тесты `GPTClient` (моки), форматтеров; интеграционные — `/gpt`→вопрос→ответ→`/exit`.
  - Артефакты: тесты в `bot/tests/unit/` и `bot/tests/integration/`.
  - Критерий готовности: тесты проходят локально и в CI.

- Этап 11: Докер/деплой
  - Основные задачи: обновить `bot/Dockerfile`, пробросить `OPENAI_*` в `docker-compose.yml`, пересобрать и развернуть.
  - Артефакты: собранный образ бота, актуальный compose.
  - Критерий готовности: контейнер стартует, GPT работает в окружении.

- Этап 12: UX‑поток, хранение истории, защита и чек‑лист
  - Основные задачи: зафиксировать UX (`/gpt`↔`/exit`), хранение истории (FSM/Redis), фича‑флаг (наличие `OPENAI_API_KEY`), ролевая модель/белые списки.
  - Артефакты: обновлённая спецификация, чек‑лист готовности.
  - Критерий готовности: сценарии понятны пользователю, история диалога обрезается и не теряется, защита включена.
- `bot/api/gpt_client.py` — реализация клиента GPT (Async, таймауты, model/temperature/max_tokens).
- `bot/core/states.py` — добавить `GPTDialogStates`.
- `bot/utils/formatters.py` — добавить `escape_markdown_v2` и `split_telegram_message`.
- `bot/handlers/gpt.py` — роутер `/gpt`, диалог, `/exit`.
- `bot/__main__.py` — инициализация `GPTClient`, регистрация `gpt_router`, (опционально) диспетчерское хранилище.

## 7) UX поток
- `/gpt` включает режим диалога (FSM), `/exit` выключает.
- В личных чатах бот отвечает на каждое текстовое сообщение в режиме.
- В группах — по упоминанию/реплаю (опционально: добавьте фильтры в хендлер).
- Ответы >4096 символов дробятся на части.
- Экранизация MarkdownV2 обязательна для корректного форматирования.

## 8) История и хранение
- Базово: храните в FSM (in‑memory/Redis‑storage). Обрезайте до 24 сообщений (12 пар).
- TTL: для Redis можно настроить, используя ключи `gpt:<chat_id>` и expire.
- Альтернатива: собственный `ConversationManager` слой над Redis с методами `get/add/trim`.

## 9) Ограничения и защита
- Rate‑limit (уже есть): добавьте проверку частоты для сообщений в состоянии GPT.
- Фича‑флаг: фактически — наличие `OPENAI_API_KEY`. При его отсутствии режим не активируется.
- Доступ по ролям: при необходимости добавьте белый список user_id в конфиг.
- Таймауты: `openai_timeout` в конфиге контролирует ожидание ответа.

## 10) Чек‑лист готовности
- `OPENAI_API_KEY` заполнен, модель/лимиты установлены.
- `gpt_client.py` и `gpt.py` добавлены, роутер подключен в `__main__.py`.
- Сообщения корректно экранируются и дробятся.
- История диалога поддерживается, обрезается по длине.
- Rate‑limit не мешает нормальному диалогу, ошибки обработаны.

## 11) Распространенные проблемы
- "Message is not modified" — используйте отправку нового сообщения (как в `safe_send_message`) или проверяйте изменение.
- Ошибки Markdown — экранируйте спецсимволы, используйте `MarkdownV2`.
- Таймауты — увеличьте `OPENAI_TIMEOUT` или сообщите пользователю об ожидании.
- Длинные ответы — обязательно разбивайте по 4096.

## 12) Быстрый старт: минимальный код
- Добавьте файлы из шагов 2–6, поставьте ключи в `.env`, установите зависимости.
- Запуск: `python -m bot`.
- Команда: `/gpt` → задайте вопрос → `/exit`.

---
Эта инструкция учитывает вашу текущую структуру (aiogram v3, роутеры, middleware, `core/config.py` с OpenAI полями). Она даёт точные правки по файлам, готовые сниппеты и тест‑план, чтобы быстро внедрить GPT без ломки существующей логики.