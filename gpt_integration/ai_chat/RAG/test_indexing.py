"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ RAG –∏ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–∞–±–æ—Ç—ã –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python -m gpt_integration.ai_chat.RAG.test_indexing <cabinet_id>

–ü—Ä–∏–º–µ—Ä:
    python -m gpt_integration.ai_chat.RAG.test_indexing 2
"""

import asyncio
import sys
import logging
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
root_dir = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(root_dir))

from gpt_integration.ai_chat.RAG.indexer import RAGIndexer
from gpt_integration.ai_chat.RAG.vector_search import VectorSearch

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


async def test_indexing(cabinet_id: int):
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –∫–∞–±–∏–Ω–µ—Ç–∞"""
    logger.info(f"üöÄ –ù–∞—á–∏–Ω–∞—é –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é –∫–∞–±–∏–Ω–µ—Ç–∞ {cabinet_id}...")
    
    indexer = RAGIndexer()
    result = await indexer.index_cabinet(cabinet_id)
    
    if result['success']:
        logger.info(f"‚úÖ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        logger.info(f"   –í—Å–µ–≥–æ —á–∞–Ω–∫–æ–≤: {result['total_chunks']}")
        if result.get('chunks_by_type'):
            for chunk_type, count in result['chunks_by_type'].items():
                logger.info(f"   - {chunk_type}: {count}")
    else:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {result.get('errors', [])}")
    
    return result


async def test_search(cabinet_id: int, query: str):
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–∏—Å–∫–∞ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î"""
    logger.info(f"üîç –¢–µ—Å—Ç–∏—Ä—É—é –ø–æ–∏—Å–∫ –¥–ª—è –∫–∞–±–∏–Ω–µ—Ç–∞ {cabinet_id}...")
    logger.info(f"   –ó–∞–ø—Ä–æ—Å: '{query}'")
    
    searcher = VectorSearch()
    results = await searcher.search_relevant_chunks(
        query_text=query,
        cabinet_id=cabinet_id,
        max_chunks=5
    )
    
    if results:
        logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤:")
        for idx, chunk in enumerate(results, 1):
            logger.info(
                f"   [{idx}] similarity={chunk['similarity']:.4f}, "
                f"type={chunk['chunk_type']}, "
                f"text_preview='{chunk['chunk_text'][:80]}...'"
            )
    else:
        logger.warning("‚ö†Ô∏è –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞–Ω–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
    
    return results


async def main():
    if len(sys.argv) < 2:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python -m gpt_integration.ai_chat.RAG.test_indexing <cabinet_id>")
        print("–ü—Ä–∏–º–µ—Ä: python -m gpt_integration.ai_chat.RAG.test_indexing 2")
        sys.exit(1)
    
    cabinet_id = int(sys.argv[1])
    
    # 1. –ó–∞–ø—É—Å—Ç–∏—Ç—å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é
    logger.info("=" * 60)
    logger.info("–®–ê–ì 1: –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö")
    logger.info("=" * 60)
    index_result = await test_indexing(cabinet_id)
    
    if not index_result['success']:
        logger.error("–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –≤—ã—à–µ.")
        return
    
    # 2. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ–∏—Å–∫ —Å —Ä–∞–∑–Ω—ã–º–∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏
    logger.info("\n" + "=" * 60)
    logger.info("–®–ê–ì 2: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–∏—Å–∫–∞")
    logger.info("=" * 60)
    
    test_queries = [
        "–∫–∞–∫–∏–µ —Ç–æ–≤–∞—Ä—ã –ø—Ä–æ–¥–∞–ª–∏—Å—å –ª—É—á—à–µ –≤—Å–µ–≥–æ",
        "—Å–∫–æ–ª—å–∫–æ –∑–∞–∫–∞–∑–æ–≤ –±—ã–ª–æ –≤—á–µ—Ä–∞",
        "–∫–∞–∫–∏–µ —Ç–æ–≤–∞—Ä—ã –Ω–∞ —Å–∫–ª–∞–¥–µ",
        "–∫–∞–∫–∏–µ –æ—Ç–∑—ã–≤—ã –ø–æ–ª—É—á–∏–ª–∏ —Ç–æ–≤–∞—Ä—ã",
        "–∫–∞–∫–∞—è –≤—ã—Ä—É—á–∫–∞ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π –º–µ—Å—è—Ü"
    ]
    
    for query in test_queries:
        logger.info(f"\nüìù –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å: '{query}'")
        await test_search(cabinet_id, query)
        logger.info("-" * 60)


if __name__ == "__main__":
    asyncio.run(main())

