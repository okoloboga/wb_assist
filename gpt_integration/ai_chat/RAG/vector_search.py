"""
Vector Search - –º–æ–¥—É–ª—å –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –≤ pgvector.

–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤ –¥–∞–Ω–Ω—ã—Ö
–Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞.
"""

import os
import logging
from typing import List, Dict, Any, Optional
from sqlalchemy.orm import Session
from sqlalchemy import text
from openai import OpenAI

from .database import RAGSessionLocal
from .models import RAGEmbedding, RAGMetadata

logger = logging.getLogger(__name__)


class VectorSearch:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤.
    
    –ü—Ä–æ—Ü–µ—Å—Å –ø–æ–∏—Å–∫–∞:
    1. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    2. –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –≤ pgvector
    3. –ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤
    """
    
    def __init__(
        self,
        openai_client: Optional[OpenAI] = None,
        embeddings_model: Optional[str] = None,
        similarity_threshold: Optional[float] = None
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–∏—Å–∫–∞.
        
        Args:
            openai_client: –ö–ª–∏–µ–Ω—Ç OpenAI (–µ—Å–ª–∏ None, —Å–æ–∑–¥–∞–µ—Ç—Å—è –Ω–æ–≤—ã–π)
            embeddings_model: –ú–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (–∏–∑ env –∏–ª–∏ default)
            similarity_threshold: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ (0-1, –∏–∑ env –∏–ª–∏ default)
        """
        self.openai_client = openai_client or OpenAI()
        self.embeddings_model = embeddings_model or os.getenv(
            "OPENAI_EMBEDDINGS_MODEL",
            "text-embedding-3-small"
        )
        self.similarity_threshold = similarity_threshold or float(
            os.getenv("RAG_SIMILARITY_THRESHOLD", "0.7")
        )
    
    def generate_query_embedding(self, query_text: str) -> List[float]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
        
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç—É –∂–µ –º–æ–¥–µ–ª—å, —á—Ç–æ –∏ –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏, –¥–ª—è –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è
        —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –≤–µ–∫—Ç–æ—Ä–æ–≤.
        
        Args:
            query_text: –¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            
        Returns:
            –í–µ–∫—Ç–æ—Ä —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ 1536
            
        Raises:
            ValueError: –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –ø—É—Å—Ç–æ–π
            Exception: –ü—Ä–∏ –æ—à–∏–±–∫–µ API OpenAI
        """
        if not query_text or not query_text.strip():
            raise ValueError("–ó–∞–ø—Ä–æ—Å –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")
        
        try:
            logger.info(f"üîÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: '{query_text[:50]}...'")
            
            # –í—ã–∑–æ–≤ OpenAI Embeddings API
            response = self.openai_client.embeddings.create(
                model=self.embeddings_model,
                input=[query_text]  # –û–¥–∏–Ω –∑–∞–ø—Ä–æ—Å
            )
            
            # –ò–∑–≤–ª–µ—á—å –≤–µ–∫—Ç–æ—Ä –∏–∑ –æ—Ç–≤–µ—Ç–∞
            embedding = response.data[0].embedding
            
            logger.info(f"‚úÖ –≠–º–±–µ–¥–¥–∏–Ω–≥ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å {len(embedding)}")
            
            return embedding
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}")
            raise
    
    def search(
        self,
        query_embedding: List[float],
        cabinet_id: int,
        chunk_types: Optional[List[str]] = None,
        limit: int = 5
    ) -> List[Dict[str, Any]]:
        """
        –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –≤ pgvector.
        
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç cosine distance –¥–ª—è –ø–æ–∏—Å–∫–∞ –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–∏—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤.
        
        Args:
            query_embedding: –≠–º–±–µ–¥–¥–∏–Ω–≥ –∑–∞–ø—Ä–æ—Å–∞ (—Å–ø–∏—Å–æ–∫ float)
            cabinet_id: ID –∫–∞–±–∏–Ω–µ—Ç–∞ (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è)
            chunk_types: –°–ø–∏—Å–æ–∫ —Ç–∏–ø–æ–≤ —á–∞–Ω–∫–æ–≤ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏:
            [
                {
                    'embedding_id': 1,
                    'metadata_id': 1,
                    'similarity': 0.85,
                    'distance': 0.15
                },
                ...
            ]
        """
        db = RAGSessionLocal()
        
        try:
            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å —Å–ø–∏—Å–æ–∫ –≤ —Å—Ç—Ä–æ–∫—É –¥–ª—è PostgreSQL vector
            embedding_str = '[' + ','.join(map(str, query_embedding)) + ']'
            
            # –ü–æ—Å—Ç—Ä–æ–∏—Ç—å SQL –∑–∞–ø—Ä–æ—Å
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º cosine distance (<#>) –∏ –≤—ã—á–∏—Å–ª—è–µ–º similarity –∫–∞–∫ 1 - distance
            if chunk_types and len(chunk_types) > 0:
                # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —Ç–∏–ø–∞–º —á–∞–Ω–∫–æ–≤
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –º–∞—Å—Å–∏–≤–∞ PostgreSQL
                chunk_types_array = '{' + ','.join(f'"{ct}"' for ct in chunk_types) + '}'
                query = text("""
                    SELECT 
                        e.id AS embedding_id,
                        e.metadata_id,
                        1 - (e.embedding <#> :query_embedding::vector) AS similarity,
                        e.embedding <#> :query_embedding::vector AS distance
                    FROM rag_embeddings e
                    JOIN rag_metadata m ON e.metadata_id = m.id
                    WHERE m.cabinet_id = :cabinet_id
                      AND m.chunk_type = ANY(:chunk_types::text[])
                    ORDER BY e.embedding <#> :query_embedding::vector
                    LIMIT :limit
                """)
                params = {
                    'query_embedding': embedding_str,
                    'cabinet_id': cabinet_id,
                    'chunk_types': chunk_types_array,
                    'limit': limit
                }
            else:
                # –ë–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ —Ç–∏–ø–∞–º
                query = text("""
                    SELECT 
                        e.id AS embedding_id,
                        e.metadata_id,
                        1 - (e.embedding <#> :query_embedding::vector) AS similarity,
                        e.embedding <#> :query_embedding::vector AS distance
                    FROM rag_embeddings e
                    JOIN rag_metadata m ON e.metadata_id = m.id
                    WHERE m.cabinet_id = :cabinet_id
                    ORDER BY e.embedding <#> :query_embedding::vector
                    LIMIT :limit
                """)
                params = {
                    'query_embedding': embedding_str,
                    'cabinet_id': cabinet_id,
                    'limit': limit
                }
            
            # –í—ã–ø–æ–ª–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å
            result = db.execute(query, params)
            rows = result.fetchall()
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            results = []
            for row in rows:
                similarity = float(row.similarity)
                
                # –ü—Ä–∏–º–µ–Ω–∏—Ç—å –ø–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
                if similarity >= self.similarity_threshold:
                    results.append({
                        'embedding_id': row.embedding_id,
                        'metadata_id': row.metadata_id,
                        'similarity': similarity,
                        'distance': float(row.distance)
                    })
            
            logger.info(
                f"üîç –ù–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ "
                f"(–ø–æ—Ä–æ–≥: {self.similarity_threshold}, –≤—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ: {len(rows)})"
            )
            
            return results
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤–µ–∫—Ç–æ—Ä–Ω–æ–º –ø–æ–∏—Å–∫–µ: {e}")
            raise
            
        finally:
            db.close()
    
    def get_metadata_for_embeddings(
        self,
        embedding_ids: List[int],
        db: Session
    ) -> List[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö embedding IDs.
        
        Args:
            embedding_ids: –°–ø–∏—Å–æ–∫ ID —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            db: –°–µ—Å—Å–∏—è –ë–î
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏:
            [
                {
                    'id': 1,
                    'embedding_id': 1,
                    'chunk_text': '...',
                    'chunk_type': 'order',
                    'source_table': 'wb_orders',
                    'source_id': 123
                },
                ...
            ]
        """
        if not embedding_ids:
            return []
        
        try:
            # –ó–∞–ø—Ä–æ—Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ JOIN
            results = db.query(
                RAGMetadata.id,
                RAGMetadata.chunk_text,
                RAGMetadata.chunk_type,
                RAGMetadata.source_table,
                RAGMetadata.source_id,
                RAGEmbedding.id.label('embedding_id')
            ).join(
                RAGEmbedding,
                RAGMetadata.id == RAGEmbedding.metadata_id
            ).filter(
                RAGEmbedding.id.in_(embedding_ids)
            ).all()
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π
            metadata_list = []
            for row in results:
                metadata_list.append({
                    'id': row.id,
                    'embedding_id': row.embedding_id,
                    'chunk_text': row.chunk_text,
                    'chunk_type': row.chunk_type,
                    'source_table': row.source_table,
                    'source_id': row.source_id
                })
            
            logger.info(f"üìã –ü–æ–ª—É—á–µ–Ω–æ {len(metadata_list)} –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö")
            
            return metadata_list
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {e}")
            raise
    
    def search_relevant_chunks(
        self,
        query_text: str,
        cabinet_id: int,
        chunk_types: Optional[List[str]] = None,
        max_chunks: int = 5
    ) -> List[Dict[str, Any]]:
        """
        –ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ –ø–æ–∏—Å–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤.
        
        –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ —ç—Ç–∞–ø—ã:
        1. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –∑–∞–ø—Ä–æ—Å–∞
        2. –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫
        3. –ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        
        Args:
            query_text: –¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            cabinet_id: ID –∫–∞–±–∏–Ω–µ—Ç–∞
            chunk_types: –¢–∏–ø—ã —á–∞–Ω–∫–æ–≤ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            max_chunks: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –∏ similarity:
            [
                {
                    'id': 1,
                    'embedding_id': 1,
                    'chunk_text': '...',
                    'chunk_type': 'order',
                    'source_table': 'wb_orders',
                    'source_id': 123,
                    'similarity': 0.85
                },
                ...
            ]
        """
        try:
            logger.info(
                f"üîç –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤: "
                f"cabinet_id={cabinet_id}, "
                f"query='{query_text[:50]}...', "
                f"chunk_types={chunk_types}, "
                f"max_chunks={max_chunks}"
            )
            
            # 1. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –∑–∞–ø—Ä–æ—Å–∞
            query_embedding = self.generate_query_embedding(query_text)
            
            # 2. –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫
            search_results = self.search(
                query_embedding=query_embedding,
                cabinet_id=cabinet_id,
                chunk_types=chunk_types,
                limit=max_chunks
            )
            
            if not search_results:
                logger.info("‚ö†Ô∏è –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞–Ω–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                return []
            
            # 3. –ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            db = RAGSessionLocal()
            try:
                embedding_ids = [r['embedding_id'] for r in search_results]
                metadata_list = self.get_metadata_for_embeddings(embedding_ids, db)
                
                # –û–±—ä–µ–¥–∏–Ω–∏—Ç—å —Å similarity
                similarity_map = {r['embedding_id']: r['similarity'] for r in search_results}
                for metadata in metadata_list:
                    embedding_id = metadata['embedding_id']
                    metadata['similarity'] = similarity_map.get(embedding_id, 0.0)
                
                # –°–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ similarity (–æ—Ç –±–æ–ª—å—à–µ–≥–æ –∫ –º–µ–Ω—å—à–µ–º—É)
                metadata_list.sort(key=lambda x: x['similarity'], reverse=True)
                
                logger.info(
                    f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(metadata_list)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤ "
                    f"(similarity: {metadata_list[0]['similarity']:.2f} - "
                    f"{metadata_list[-1]['similarity']:.2f})"
                )
                
                return metadata_list
                
            finally:
                db.close()
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤: {e}")
            # –í–µ—Ä–Ω—É—Ç—å –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –ø—Ä–∏ –æ—à–∏–±–∫–µ (fallback)
            return []

