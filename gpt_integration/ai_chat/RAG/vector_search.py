"""
Vector Search - –º–æ–¥—É–ª—å –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –≤ pgvector.

–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤ –¥–∞–Ω–Ω—ã—Ö
–Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞.
"""

import os
import logging
from typing import List, Dict, Any, Optional
from sqlalchemy.orm import Session
from sqlalchemy import text
from openai import OpenAI

from .database import RAGSessionLocal
from .models import RAGEmbedding, RAGMetadata

logger = logging.getLogger(__name__)


class VectorSearch:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤.
    
    –ü—Ä–æ—Ü–µ—Å—Å –ø–æ–∏—Å–∫–∞:
    1. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    2. –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –≤ pgvector
    3. –ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤
    """
    
    def __init__(
        self,
        openai_client: Optional[OpenAI] = None,
        embeddings_model: Optional[str] = None,
        similarity_threshold: Optional[float] = None
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–∏—Å–∫–∞.
        
        Args:
            openai_client: –ö–ª–∏–µ–Ω—Ç OpenAI (–µ—Å–ª–∏ None, —Å–æ–∑–¥–∞–µ—Ç—Å—è –Ω–æ–≤—ã–π)
            embeddings_model: –ú–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (–∏–∑ env –∏–ª–∏ default)
            similarity_threshold: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ (0-1, –∏–∑ env –∏–ª–∏ default)
        """
        if openai_client is None:
            api_key = os.getenv("OPENAI_API_KEY")
            base_url_raw = os.getenv("OPENAI_BASE_URL")
            base_url = None
            if base_url_raw and base_url_raw.strip():
                base_url_clean = base_url_raw.strip()
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ URL –≤–∞–ª–∏–¥–Ω—ã–π (–Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å http:// –∏–ª–∏ https://)
                if base_url_clean.startswith(("http://", "https://")):
                    base_url = base_url_clean
            client_kwargs = {}
            if api_key:
                client_kwargs["api_key"] = api_key
            if base_url:
                client_kwargs["base_url"] = base_url
            self.openai_client = OpenAI(**client_kwargs) if client_kwargs else OpenAI()
        else:
            self.openai_client = openai_client
        self.embeddings_model = embeddings_model or os.getenv(
            "OPENAI_EMBEDDINGS_MODEL",
            "text-embedding-3-small"
        )
        self.similarity_threshold = similarity_threshold or float(
            os.getenv("RAG_SIMILARITY_THRESHOLD", "0.5")
        )
    
    def generate_query_embedding(self, query_text: str) -> List[float]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
        
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç—É –∂–µ –º–æ–¥–µ–ª—å, —á—Ç–æ –∏ –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏, –¥–ª—è –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è
        —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –≤–µ–∫—Ç–æ—Ä–æ–≤.
        
        Args:
            query_text: –¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            
        Returns:
            –í–µ–∫—Ç–æ—Ä —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ 1536
            
        Raises:
            ValueError: –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –ø—É—Å—Ç–æ–π
            Exception: –ü—Ä–∏ –æ—à–∏–±–∫–µ API OpenAI
        """
        if not query_text or not query_text.strip():
            raise ValueError("–ó–∞–ø—Ä–æ—Å –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")
        
        try:
            logger.info(f"üîÑ Generating embedding for query: '{query_text[:50]}...'")
            
            # –í—ã–∑–æ–≤ OpenAI Embeddings API
            response = self.openai_client.embeddings.create(
                model=self.embeddings_model,
                input=[query_text]  # –û–¥–∏–Ω –∑–∞–ø—Ä–æ—Å
            )
            
            # –ò–∑–≤–ª–µ—á—å –≤–µ–∫—Ç–æ—Ä –∏–∑ –æ—Ç–≤–µ—Ç–∞
            embedding = response.data[0].embedding
            
            logger.info(f"‚úÖ Embedding generated: dimension {len(embedding)}")
            
            return embedding
            
        except Exception as e:
            logger.error(f"‚ùå Error generating embedding: {e}")
            raise
    
    def search(
        self,
        query_embedding: List[float],
        cabinet_id: int,
        chunk_types: Optional[List[str]] = None,
        limit: int = 5
    ) -> List[Dict[str, Any]]:
        """
        –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –≤ pgvector.
        
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç cosine distance –¥–ª—è –ø–æ–∏—Å–∫–∞ –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–∏—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤.
        
        Args:
            query_embedding: –≠–º–±–µ–¥–¥–∏–Ω–≥ –∑–∞–ø—Ä–æ—Å–∞ (—Å–ø–∏—Å–æ–∫ float)
            cabinet_id: ID –∫–∞–±–∏–Ω–µ—Ç–∞ (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è)
            chunk_types: –°–ø–∏—Å–æ–∫ —Ç–∏–ø–æ–≤ —á–∞–Ω–∫–æ–≤ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏:
            [
                {
                    'embedding_id': 1,
                    'metadata_id': 1,
                    'similarity': 0.85,
                    'distance': 0.15
                },
                ...
            ]
        """
        db = RAGSessionLocal()
        
        try:
            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å —Å–ø–∏—Å–æ–∫ –≤ —Å—Ç—Ä–æ–∫—É –¥–ª—è PostgreSQL vector
            embedding_str = '[' + ','.join(map(str, query_embedding)) + ']'
            
            # –ü–æ—Å—Ç—Ä–æ–∏—Ç—å SQL –∑–∞–ø—Ä–æ—Å
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º cosine distance (<#>) –∏ –≤—ã—á–∏—Å–ª—è–µ–º similarity –∫–∞–∫ 1 - distance
            # –í–∞–∂–Ω–æ: –∏—Å–ø–æ–ª—å–∑—É–µ–º f-string –¥–ª—è embedding_str, —Ç–∞–∫ –∫–∞–∫ SQLAlchemy –Ω–µ –º–æ–∂–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ
            # –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å placeholder —Å ::vector –∏–∑-–∑–∞ –¥–≤–æ–π–Ω–æ–≥–æ –¥–≤–æ–µ—Ç–æ—á–∏—è
            if chunk_types and len(chunk_types) > 0:
                # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —Ç–∏–ø–∞–º —á–∞–Ω–∫–æ–≤
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –º–∞—Å—Å–∏–≤–∞ PostgreSQL
                chunk_types_array = '{' + ','.join(f'"{ct}"' for ct in chunk_types) + '}'
                query = text(f"""
                    SELECT 
                        e.id AS embedding_id,
                        e.metadata_id,
                        1 - (e.embedding <#> '{embedding_str}'::vector) AS similarity,
                        e.embedding <#> '{embedding_str}'::vector AS distance
                    FROM rag_embeddings e
                    JOIN rag_metadata m ON e.metadata_id = m.id
                    WHERE m.cabinet_id = :cabinet_id
                      AND m.chunk_type = ANY(:chunk_types::text[])
                    ORDER BY e.embedding <#> '{embedding_str}'::vector
                    LIMIT :limit
                """)
                params = {
                    'cabinet_id': cabinet_id,
                    'chunk_types': chunk_types_array,
                    'limit': limit
                }
            else:
                # –ë–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ —Ç–∏–ø–∞–º
                query = text(f"""
                    SELECT 
                        e.id AS embedding_id,
                        e.metadata_id,
                        1 - (e.embedding <#> '{embedding_str}'::vector) AS similarity,
                        e.embedding <#> '{embedding_str}'::vector AS distance
                    FROM rag_embeddings e
                    JOIN rag_metadata m ON e.metadata_id = m.id
                    WHERE m.cabinet_id = :cabinet_id
                    ORDER BY e.embedding <#> '{embedding_str}'::vector
                    LIMIT :limit
                """)
                params = {
                    'cabinet_id': cabinet_id,
                    'limit': limit
                }
            
            # –í—ã–ø–æ–ª–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å
            logger.info(
                f"üìä Executing vector search: "
                f"cabinet_id={cabinet_id}, "
                f"limit={limit}, "
                f"chunk_types={chunk_types if chunk_types else 'all'}, "
                f"similarity_threshold={self.similarity_threshold}"
            )
            
            result = db.execute(query, params)
            rows = result.fetchall()
            
            logger.info(f"üìà Retrieved {len(rows)} results from DB (before threshold filtering)")
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            results = []
            filtered_out = []
            for idx, row in enumerate(rows):
                similarity = float(row.similarity)
                distance = float(row.distance)
                
                logger.debug(
                    f"  [{idx+1}/{len(rows)}] embedding_id={row.embedding_id}, "
                    f"metadata_id={row.metadata_id}, "
                    f"similarity={similarity:.4f}, "
                    f"distance={distance:.4f}"
                )
                
                # –ü—Ä–∏–º–µ–Ω–∏—Ç—å –ø–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
                if similarity >= self.similarity_threshold:
                    results.append({
                        'embedding_id': row.embedding_id,
                        'metadata_id': row.metadata_id,
                        'similarity': similarity,
                        'distance': distance
                    })
                else:
                    filtered_out.append({
                        'embedding_id': row.embedding_id,
                        'similarity': similarity,
                        'distance': distance
                    })
            
            logger.info(
                f"‚úÖ Filtering results: "
                f"passed={len(results)}, "
                f"filtered_out={len(filtered_out)}, "
                f"threshold={self.similarity_threshold}"
            )
            
            if results:
                logger.info(
                    f"üìä Similarity range for passed results: "
                    f"min={min(r['similarity'] for r in results):.4f}, "
                    f"max={max(r['similarity'] for r in results):.4f}, "
                    f"avg={sum(r['similarity'] for r in results) / len(results):.4f}"
                )
            
            if filtered_out:
                logger.info(
                    f"‚ö†Ô∏è Filtered out results (below threshold {self.similarity_threshold}): "
                    f"min={min(f['similarity'] for f in filtered_out):.4f}, "
                    f"max={max(f['similarity'] for f in filtered_out):.4f}"
                )
            
            return results
            
        except Exception as e:
            logger.error(f"‚ùå Error in vector search: {e}")
            raise
            
        finally:
            db.close()
    
    def get_metadata_for_embeddings(
        self,
        embedding_ids: List[int],
        db: Session
    ) -> List[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö embedding IDs.
        
        Args:
            embedding_ids: –°–ø–∏—Å–æ–∫ ID —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            db: –°–µ—Å—Å–∏—è –ë–î
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏:
            [
                {
                    'id': 1,
                    'embedding_id': 1,
                    'chunk_text': '...',
                    'chunk_type': 'order',
                    'source_table': 'wb_orders',
                    'source_id': 123
                },
                ...
            ]
        """
        if not embedding_ids:
            return []
        
        try:
            # –ó–∞–ø—Ä–æ—Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ JOIN
            results = db.query(
                RAGMetadata.id,
                RAGMetadata.chunk_text,
                RAGMetadata.chunk_type,
                RAGMetadata.source_table,
                RAGMetadata.source_id,
                RAGEmbedding.id.label('embedding_id')
            ).join(
                RAGEmbedding,
                RAGMetadata.id == RAGEmbedding.metadata_id
            ).filter(
                RAGEmbedding.id.in_(embedding_ids)
            ).all()
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π
            metadata_list = []
            for row in results:
                metadata_list.append({
                    'id': row.id,
                    'embedding_id': row.embedding_id,
                    'chunk_text': row.chunk_text,
                    'chunk_type': row.chunk_type,
                    'source_table': row.source_table,
                    'source_id': row.source_id
                })
            
            logger.info(f"üìã Retrieved {len(metadata_list)} metadata records")
            
            return metadata_list
            
        except Exception as e:
            logger.error(f"‚ùå Error retrieving metadata: {e}")
            raise
    
    def search_relevant_chunks(
        self,
        query_text: str,
        cabinet_id: int,
        chunk_types: Optional[List[str]] = None,
        max_chunks: int = 5
    ) -> List[Dict[str, Any]]:
        """
        –ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ –ø–æ–∏—Å–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤.
        
        –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ —ç—Ç–∞–ø—ã:
        1. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –∑–∞–ø—Ä–æ—Å–∞
        2. –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫
        3. –ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        
        Args:
            query_text: –¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            cabinet_id: ID –∫–∞–±–∏–Ω–µ—Ç–∞
            chunk_types: –¢–∏–ø—ã —á–∞–Ω–∫–æ–≤ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            max_chunks: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –∏ similarity:
            [
                {
                    'id': 1,
                    'embedding_id': 1,
                    'chunk_text': '...',
                    'chunk_type': 'order',
                    'source_table': 'wb_orders',
                    'source_id': 123,
                    'similarity': 0.85
                },
                ...
            ]
        """
        try:
            logger.info(
                f"üîç Starting search for relevant chunks:\n"
                f"  üìù Query: '{query_text}'\n"
                f"  üè¢ Cabinet ID: {cabinet_id}\n"
                f"  üì¶ Chunk types: {chunk_types if chunk_types else 'all'}\n"
                f"  üî¢ Max results: {max_chunks}\n"
                f"  üìä Similarity threshold: {self.similarity_threshold}"
            )
            
            # 1. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –∑–∞–ø—Ä–æ—Å–∞
            query_embedding = self.generate_query_embedding(query_text)
            
            # 2. –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫
            search_results = self.search(
                query_embedding=query_embedding,
                cabinet_id=cabinet_id,
                chunk_types=chunk_types,
                limit=max_chunks
            )
            
            if not search_results:
                logger.warning(
                    f"‚ö†Ô∏è No relevant chunks found for query '{query_text[:100]}...' "
                    f"(cabinet_id={cabinet_id}, threshold={self.similarity_threshold})"
                )
                return []
            
            logger.info(
                f"üìã Found {len(search_results)} results after filtering, "
                f"fetching metadata..."
            )
            
            # 3. –ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            db = RAGSessionLocal()
            try:
                embedding_ids = [r['embedding_id'] for r in search_results]
                logger.debug(f"üîç –ó–∞–ø—Ä–∞—à–∏–≤–∞—é –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è {len(embedding_ids)} embedding IDs: {embedding_ids}")
                
                metadata_list = self.get_metadata_for_embeddings(embedding_ids, db)
                
                # –û–±—ä–µ–¥–∏–Ω–∏—Ç—å —Å similarity
                similarity_map = {r['embedding_id']: r['similarity'] for r in search_results}
                for metadata in metadata_list:
                    embedding_id = metadata['embedding_id']
                    metadata['similarity'] = similarity_map.get(embedding_id, 0.0)
                
                # –°–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ similarity (–æ—Ç –±–æ–ª—å—à–µ–≥–æ –∫ –º–µ–Ω—å—à–µ–º—É)
                metadata_list.sort(key=lambda x: x['similarity'], reverse=True)
                
                logger.info(
                    f"‚úÖ Final search results:\n"
                    f"  üìä Total found: {len(metadata_list)} chunks\n"
                    f"  üìà Similarity range: {metadata_list[0]['similarity']:.4f} - "
                    f"{metadata_list[-1]['similarity']:.4f}\n"
                    f"  üìù Chunk types: {', '.join(set(m['chunk_type'] for m in metadata_list))}"
                )
                
                # –î–µ—Ç–∞–ª—å–Ω—ã–π –ª–æ–≥ –ø–æ –∫–∞–∂–¥–æ–º—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É
                for idx, metadata in enumerate(metadata_list, 1):
                    logger.debug(
                        f"  [{idx}] similarity={metadata['similarity']:.4f}, "
                        f"type={metadata['chunk_type']}, "
                        f"source={metadata['source_table']}:{metadata['source_id']}, "
                        f"text_preview='{metadata['chunk_text'][:50]}...'"
                    )
                
                return metadata_list
                
            finally:
                db.close()
                
        except Exception as e:
            logger.error(f"‚ùå Error searching relevant chunks: {e}")
            # –í–µ—Ä–Ω—É—Ç—å –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –ø—Ä–∏ –æ—à–∏–±–∫–µ (fallback)
            return []

