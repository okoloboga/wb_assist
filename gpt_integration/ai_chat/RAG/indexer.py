"""
RAG Indexer - —Å–µ—Ä–≤–∏—Å –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î.

–ú–æ–¥—É–ª—å –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–π –ë–î, —Å–æ–∑–¥–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —á–∞–Ω–∫–æ–≤,
–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Ö –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î.
"""

import os
import hashlib
import logging
from typing import List, Dict, Any, Optional
from datetime import datetime
from sqlalchemy.orm import Session
from openai import OpenAI

from .database import RAGSessionLocal
from .models import RAGMetadata, RAGEmbedding, RAGIndexStatus
from ..tools.db_pool import get_asyncpg_pool

logger = logging.getLogger(__name__)


class RAGIndexer:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–π –ë–î –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î.
    
    –ü—Ä–æ—Ü–µ—Å—Å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏:
    1. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–π –ë–î
    2. –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —á–∞–Ω–∫–æ–≤
    3. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —á–µ—Ä–µ–∑ OpenAI API
    4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î
    """
    
    def __init__(
        self,
        openai_client: Optional[OpenAI] = None,
        embeddings_model: Optional[str] = None,
        batch_size: Optional[int] = None
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω–¥–µ–∫—Å–µ—Ä–∞.
        
        Args:
            openai_client: –ö–ª–∏–µ–Ω—Ç OpenAI (–µ—Å–ª–∏ None, —Å–æ–∑–¥–∞–µ—Ç—Å—è –Ω–æ–≤—ã–π)
            embeddings_model: –ú–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (–∏–∑ env –∏–ª–∏ default)
            batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (–∏–∑ env –∏–ª–∏ default)
        """
        if openai_client is None:
            api_key = os.getenv("OPENAI_API_KEY")
            base_url_raw = os.getenv("OPENAI_BASE_URL")
            base_url = None
            if base_url_raw and base_url_raw.strip():
                base_url_clean = base_url_raw.strip()
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ URL –≤–∞–ª–∏–¥–Ω—ã–π (–Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å http:// –∏–ª–∏ https://)
                if base_url_clean.startswith(("http://", "https://")):
                    base_url = base_url_clean
            client_kwargs = {}
            if api_key:
                client_kwargs["api_key"] = api_key
            if base_url:
                client_kwargs["base_url"] = base_url
            self.openai_client = OpenAI(**client_kwargs) if client_kwargs else OpenAI()
        else:
            self.openai_client = openai_client
        self.embeddings_model = embeddings_model or os.getenv(
            "OPENAI_EMBEDDINGS_MODEL",
            "text-embedding-3-small"
        )
        self.batch_size = batch_size or int(os.getenv("RAG_EMBEDDING_BATCH_SIZE", "100"))

    @staticmethod
    def calculate_chunk_hash(chunk_text: str) -> str:
        """
        –í—ã—á–∏—Å–ª–∏—Ç—å SHA256 hash –æ—Ç chunk_text.

        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è hash-based change detection:
        - –ï—Å–ª–∏ hash –Ω–µ –∏–∑–º–µ–Ω–∏–ª—Å—è, —Ç–æ chunk_text –Ω–µ –∏–∑–º–µ–Ω–∏–ª—Å—è
        - –ú–æ–∂–Ω–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ (—ç–∫–æ–Ω–æ–º–∏—è API)

        Args:
            chunk_text: –¢–µ–∫—Å—Ç —á–∞–Ω–∫–∞

        Returns:
            SHA256 hash –≤ hex —Ñ–æ—Ä–º–∞—Ç–µ (64 —Å–∏–º–≤–æ–ª–∞)
        """
        return hashlib.sha256(chunk_text.encode('utf-8')).hexdigest()
        
    async def extract_data_from_main_db(self, cabinet_id: int) -> Dict[str, List[Dict[str, Any]]]:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–π –ë–î –¥–ª—è –∫–∞–±–∏–Ω–µ—Ç–∞.
        
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç asyncpg –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ –æ—Å–Ω–æ–≤–Ω–æ–π –ë–î.
        –ü–æ–¥–∫–ª—é—á–∞–µ—Ç—Å—è –∫ –æ—Å–Ω–æ–≤–Ω–æ–π –ë–î —á–µ—Ä–µ–∑ DATABASE_URL (–Ω–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π).
        
        Args:
            cabinet_id: ID –∫–∞–±–∏–Ω–µ—Ç–∞ Wildberries
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –ø–æ —Ç–∏–ø–∞–º:
            {
                'orders': [...],
                'products': [...],
                'stocks': [...],
                'reviews': [...],
                'sales': [...]
            }
        """
        # –ü–æ–ª—É—á–∏—Ç—å –ø—É–ª –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π –∫ –æ—Å–Ω–æ–≤–Ω–æ–π –ë–î
        pool = await get_asyncpg_pool()
        
        data = {
            'orders': [],
            'products': [],
            'stocks': [],
            'reviews': [],
            'sales': []
        }
        
        try:
            async with pool.acquire() as conn:
                # 1. –ó–∞–∫–∞–∑—ã
                orders = await conn.fetch("""
                    SELECT id, order_id, nm_id, name, size, price, total_price, 
                           order_date, status
                    FROM wb_orders
                    WHERE cabinet_id = $1
                      AND order_date >= NOW() - INTERVAL '90 days'
                    ORDER BY order_date DESC
                """, cabinet_id)
                data['orders'] = [dict(row) for row in orders]
                
                # 2. –¢–æ–≤–∞—Ä—ã
                products = await conn.fetch("""
                    SELECT nm_id, name, brand, category, price, rating, reviews_count
                    FROM wb_products
                    WHERE cabinet_id = $1
                      AND is_active = true
                """, cabinet_id)
                data['products'] = [dict(row) for row in products]
                
                # 3. –û—Å—Ç–∞—Ç–∫–∏
                stocks = await conn.fetch("""
                    SELECT nm_id, size, warehouse_name, quantity, name
                    FROM wb_stocks
                    WHERE cabinet_id = $1
                      AND quantity > 0
                """, cabinet_id)
                data['stocks'] = [dict(row) for row in stocks]
                
                # 4. –û—Ç–∑—ã–≤—ã
                reviews = await conn.fetch("""
                    SELECT id, nm_id, rating, text, created_at
                    FROM wb_reviews
                    WHERE cabinet_id = $1
                      AND created_at >= NOW() - INTERVAL '90 days'
                    ORDER BY created_at DESC
                """, cabinet_id)
                data['reviews'] = [dict(row) for row in reviews]
                
                # 5. –ü—Ä–æ–¥–∞–∂–∏
                sales = await conn.fetch("""
                    SELECT id, nm_id, type, sale_date, amount, product_name
                    FROM wb_sales
                    WHERE cabinet_id = $1
                      AND sale_date >= NOW() - INTERVAL '90 days'
                    ORDER BY sale_date DESC
                """, cabinet_id)
                data['sales'] = [dict(row) for row in sales]
                
        except Exception as e:
            logger.error(f"‚ùå Error extracting data for cabinet {cabinet_id}: {e}")
            raise
        
        logger.info(
            f"üìä Extracted data for cabinet {cabinet_id}: "
            f"orders={len(data['orders'])}, products={len(data['products'])}, "
            f"stocks={len(data['stocks'])}, reviews={len(data['reviews'])}, "
            f"sales={len(data['sales'])}"
        )
        
        return data
    
    def _create_order_chunk(self, order: Dict[str, Any], product_name: Optional[str] = None) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —á–∞–Ω–∫–∞ –¥–ª—è –∑–∞–∫–∞–∑–∞."""
        name = product_name or order.get('name', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–æ–≤–∞—Ä')
        order_id = order.get('order_id', order.get('id', 'N/A'))
        order_date = order.get('order_date')
        if isinstance(order_date, datetime):
            order_date = order_date.strftime('%Y-%m-%d')
        elif order_date:
            order_date = str(order_date)
        else:
            order_date = 'N/A'
        
        price = order.get('price', 0) or 0
        if not isinstance(price, (int, float)):
            price = 0
        
        chunk_text = (
            f"–ó–∞–∫–∞–∑ #{order_id} –æ—Ç {order_date}: "
            f"—Ç–æ–≤–∞—Ä '{name}' (nm_id: {order.get('nm_id', 'N/A')}), "
            f"—Ä–∞–∑–º–µ—Ä {order.get('size', 'N/A')}, "
            f"—Ü–µ–Ω–∞ {price:.2f}‚ÇΩ, "
            f"—Å—Ç–∞—Ç—É—Å: {order.get('status', 'N/A')}"
        )
        
        return {
            'chunk_type': 'order',
            'source_table': 'wb_orders',
            'source_id': order.get('id'),
            'chunk_text': chunk_text
        }
    
    def _create_product_chunk(self, product: Dict[str, Any]) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —á–∞–Ω–∫–∞ –¥–ª—è —Ç–æ–≤–∞—Ä–∞."""
        name = product.get('name', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–æ–≤–∞—Ä')
        brand = product.get('brand', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –±—Ä–µ–Ω–¥')
        category = product.get('category', '–ë–µ–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏')
        rating = product.get('rating', 0) or 0
        reviews_count = product.get('reviews_count', 0) or 0
        price = product.get('price', 0) or 0
        nm_id = product.get('nm_id', 'N/A')
        
        if not isinstance(rating, (int, float)):
            rating = 0
        if not isinstance(reviews_count, (int, float)):
            reviews_count = 0
        if not isinstance(price, (int, float)):
            price = 0
        
        # –£–ª—É—á—à–µ–Ω–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å –±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∏ —Å–∏–Ω–æ–Ω–∏–º–æ–≤
        # –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–∏—Å–∫–∞ –ø–æ —Ä–∞–∑–ª–∏—á–Ω—ã–º —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞–º –∑–∞–ø—Ä–æ—Å–æ–≤
        chunk_text = (
            f"–¢–æ–≤–∞—Ä –ø—Ä–æ–¥—É–∫—Ç '{name}' –∞—Ä—Ç–∏–∫—É–ª nm_id {nm_id}. "
            f"–ë—Ä–µ–Ω–¥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å: {brand}. "
            f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è —Ç–∏–ø —Ç–æ–≤–∞—Ä–∞: {category}. "
            f"–†–µ–π—Ç–∏–Ω–≥ –æ—Ü–µ–Ω–∫–∞: {rating:.1f} –∏–∑ 5. "
            f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤: {reviews_count}. "
            f"–¶–µ–Ω–∞ —Å—Ç–æ–∏–º–æ—Å—Ç—å: {price:.2f} —Ä—É–±–ª–µ–π. "
            f"–ê—Ä—Ç–∏–∫—É–ª nm_id: {nm_id}"
        )
        
        return {
            'chunk_type': 'product',
            'source_table': 'wb_products',
            'source_id': nm_id,
            'chunk_text': chunk_text
        }
    
    def _create_stock_chunk(self, stock: Dict[str, Any], product_name: Optional[str] = None) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —á–∞–Ω–∫–∞ –¥–ª—è –æ—Å—Ç–∞—Ç–∫–∞ —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞."""
        name = product_name or '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–æ–≤–∞—Ä'
        warehouse = stock.get('warehouse_name', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Å–∫–ª–∞–¥')
        quantity = stock.get('quantity', 0) or 0
        size = stock.get('size', 'N/A')
        nm_id = stock.get('nm_id', 'N/A')

        if not isinstance(quantity, (int, float)):
            quantity = 0

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –æ—Å—Ç–∞—Ç–∫–∞ –∏ –¥–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        status_keywords = []
        if quantity == 0:
            status_keywords = ["–Ω—É–ª–µ–≤–æ–π –æ—Å—Ç–∞—Ç–æ–∫", "—Ç–æ–≤–∞—Ä –∑–∞–∫–æ–Ω—á–∏–ª—Å—è", "–°–†–û–ß–ù–û –ø–æ–ø–æ–ª–Ω–∏—Ç—å", "–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –æ—Å—Ç–∞—Ç–æ–∫"]
        elif quantity <= 5:
            status_keywords = ["–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –æ—Å—Ç–∞—Ç–æ–∫", "–æ—á–µ–Ω—å –º–∞–ª–æ", "—Å—Ä–æ—á–Ω–æ –ø–æ–ø–æ–ª–Ω–∏—Ç—å", "—Ç—Ä–µ–±—É–µ—Ç –ø–æ–ø–æ–ª–Ω–µ–Ω–∏—è"]
        elif quantity <= 10:
            status_keywords = ["–Ω–∏–∑–∫–∏–π –æ—Å—Ç–∞—Ç–æ–∫", "–º–∞–ª–æ —Ç–æ–≤–∞—Ä–∞", "–Ω—É–∂–Ω–æ –ø–æ–ø–æ–ª–Ω–∏—Ç—å", "—Å–∫–æ—Ä–æ –∑–∞–∫–æ–Ω—á–∏—Ç—Å—è"]
        elif quantity <= 20:
            status_keywords = ["–Ω–µ–≤—ã—Å–æ–∫–∏–π –æ—Å—Ç–∞—Ç–æ–∫", "—Å—Ç–æ–∏—Ç –ø–æ–ø–æ–ª–Ω–∏—Ç—å", "–∑–∞–ø–∞—Å –Ω–∞ –∏—Å—Ö–æ–¥–µ"]
        else:
            status_keywords = ["–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π –æ—Å—Ç–∞—Ç–æ–∫", "–∑–∞–ø–∞—Å –≤ –Ω–æ—Ä–º–µ"]

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —á–∞–Ω–∫–∞ —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
        chunk_text = (
            f"–û—Å—Ç–∞—Ç–æ–∫ –∑–∞–ø–∞—Å —Ç–æ–≤–∞—Ä–∞ '{name}' –∞—Ä—Ç–∏–∫—É–ª nm_id {nm_id}: "
            f"—Ä–∞–∑–º–µ—Ä {size}, —Å–∫–ª–∞–¥ {warehouse}, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ {int(quantity)} —à—Ç—É–∫. "
            f"–°—Ç–∞—Ç—É—Å: {', '.join(status_keywords)}."
        )

        return {
            'chunk_type': 'stock',
            'source_table': 'wb_stocks',
            'source_id': nm_id,
            'chunk_text': chunk_text
        }
    
    def _create_review_chunk(self, review: Dict[str, Any], product_name: Optional[str] = None) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —á–∞–Ω–∫–∞ –¥–ª—è –æ—Ç–∑—ã–≤–∞."""
        name = product_name or '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–æ–≤–∞—Ä'
        rating = review.get('rating', 0) or 0
        text = review.get('text', '–ë–µ–∑ —Ç–µ–∫—Å—Ç–∞') or '–ë–µ–∑ —Ç–µ–∫—Å—Ç–∞'
        created_at = review.get('created_at')
        
        if isinstance(created_at, datetime):
            created_at = created_at.strftime('%Y-%m-%d')
        elif created_at:
            created_at = str(created_at)
        else:
            created_at = 'N/A'
        
        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª–∏–Ω—ã —Ç–µ–∫—Å—Ç–∞ –æ—Ç–∑—ã–≤–∞ (—á—Ç–æ–±—ã —á–∞–Ω–∫ –Ω–µ –±—ã–ª —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–º)
        if len(text) > 200:
            text = text[:200] + '...'
        
        if not isinstance(rating, (int, float)):
            rating = 0
        
        chunk_text = (
            f"–û—Ç–∑—ã–≤ –Ω–∞ —Ç–æ–≤–∞—Ä '{name}' (nm_id: {review.get('nm_id', 'N/A')}): "
            f"—Ä–µ–π—Ç–∏–Ω–≥ {int(rating)}‚≠ê, –¥–∞—Ç–∞: {created_at}, —Ç–µ–∫—Å—Ç: '{text}'"
        )
        
        return {
            'chunk_type': 'review',
            'source_table': 'wb_reviews',
            'source_id': review.get('id'),
            'chunk_text': chunk_text
        }
    
    def _create_sale_chunk(self, sale: Dict[str, Any], product_name: Optional[str] = None) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —á–∞–Ω–∫–∞ –¥–ª—è –ø—Ä–æ–¥–∞–∂–∏."""
        name = product_name or '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–æ–≤–∞—Ä'
        sale_type = sale.get('type', 'N/A')
        sale_date = sale.get('sale_date')
        
        if isinstance(sale_date, datetime):
            sale_date = sale_date.strftime('%Y-%m-%d')
        elif sale_date:
            sale_date = str(sale_date)
        else:
            sale_date = 'N/A'
        
        amount = sale.get('amount', 0) or 0
        if not isinstance(amount, (int, float)):
            amount = 0
        
        chunk_text = (
            f"–ü—Ä–æ–¥–∞–∂–∞ —Ç–æ–≤–∞—Ä–∞ '{name}' (nm_id: {sale.get('nm_id', 'N/A')}) –æ—Ç {sale_date}: "
            f"—Ç–∏–ø - {sale_type}, —Å—É–º–º–∞: {amount:.2f}‚ÇΩ"
        )
        
        return {
            'chunk_type': 'sale',
            'source_table': 'wb_sales',
            'source_id': sale.get('id'),
            'chunk_text': chunk_text
        }
    
    def create_chunks(self, data: Dict[str, List[Dict[str, Any]]]) -> List[Dict[str, Any]]:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —á–∞–Ω–∫–æ–≤ –∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
        
        –°–æ–∑–¥–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å –Ω–∞–∑–≤–∞–Ω–∏–π —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –¥—Ä—É–≥–∏—Ö —á–∞–Ω–∫–∞—Ö.
        
        Args:
            data: –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –ø–æ —Ç–∏–ø–∞–º
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å —á–∞–Ω–∫–∞–º–∏:
            [
                {
                    'chunk_type': 'order',
                    'source_table': 'wb_orders',
                    'source_id': 123,
                    'chunk_text': '–ó–∞–∫–∞–∑ #12345...'
                },
                ...
            ]
        """
        chunks = []
        
        # –°–æ–∑–¥–∞—Ç—å —Å–ª–æ–≤–∞—Ä—å –Ω–∞–∑–≤–∞–Ω–∏–π —Ç–æ–≤–∞—Ä–æ–≤ (nm_id -> name)
        product_names = {}
        for product in data.get('products', []):
            nm_id = product.get('nm_id')
            if nm_id:
                product_names[nm_id] = product.get('name', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–æ–≤–∞—Ä')
        
        # –°–æ–∑–¥–∞—Ç—å —á–∞–Ω–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ –¥–∞–Ω–Ω—ã—Ö
        for order in data.get('orders', []):
            nm_id = order.get('nm_id')
            product_name = product_names.get(nm_id) if nm_id else None
            chunks.append(self._create_order_chunk(order, product_name))
        
        for product in data.get('products', []):
            chunks.append(self._create_product_chunk(product))
        
        for stock in data.get('stocks', []):
            nm_id = stock.get('nm_id')
            product_name = product_names.get(nm_id) if nm_id else None
            chunks.append(self._create_stock_chunk(stock, product_name))
        
        for review in data.get('reviews', []):
            nm_id = review.get('nm_id')
            product_name = product_names.get(nm_id) if nm_id else None
            chunks.append(self._create_review_chunk(review, product_name))
        
        for sale in data.get('sales', []):
            nm_id = sale.get('nm_id')
            product_name = product_names.get(nm_id) if nm_id else None
            chunks.append(self._create_sale_chunk(sale, product_name))
        
        logger.info(f"üìù Created {len(chunks)} chunks from data")
        
        return chunks
    
    def generate_embeddings(self, chunks: List[str]) -> List[List[float]]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è —Å–ø–∏—Å–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —á–∞–Ω–∫–æ–≤.

        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç batch processing –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ API.
        –° retry –ª–æ–≥–∏–∫–æ–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –±–∞—Ç—á–∞ –æ—Ç–¥–µ–ª—å–Ω–æ.

        Args:
            chunks: –°–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —á–∞–Ω–∫–æ–≤

        Returns:
            –°–ø–∏—Å–æ–∫ –≤–µ–∫—Ç–æ—Ä–æ–≤ (–∫–∞–∂–¥—ã–π –≤–µ–∫—Ç–æ—Ä - —Å–ø–∏—Å–æ–∫ –∏–∑ 1536 float)
        """
        import time

        if not chunks:
            return []

        all_embeddings = []
        total_chunks = len(chunks)
        failed_batches = []

        # –†–∞–∑–±–∏—Ç—å –Ω–∞ –±–∞—Ç—á–∏
        for i in range(0, total_chunks, self.batch_size):
            batch = chunks[i:i + self.batch_size]
            batch_num = (i // self.batch_size) + 1
            total_batches = (total_chunks + self.batch_size - 1) // self.batch_size

            logger.info(
                f"üîÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: –±–∞—Ç—á {batch_num}/{total_batches} "
                f"({len(batch)} —á–∞–Ω–∫–æ–≤)"
            )

            # Retry –ª–æ–≥–∏–∫–∞ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –±–∞—Ç—á–∞
            max_retries = 5
            retry_delay = 2  # –ù–∞—á–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö

            for attempt in range(max_retries):
                try:
                    # –í—ã–∑–æ–≤ OpenAI Embeddings API
                    response = self.openai_client.embeddings.create(
                        model=self.embeddings_model,
                        input=batch
                    )

                    # –ò–∑–≤–ª–µ—á—å –≤–µ–∫—Ç–æ—Ä—ã –∏–∑ –æ—Ç–≤–µ—Ç–∞
                    batch_embeddings = [item.embedding for item in response.data]
                    all_embeddings.extend(batch_embeddings)

                    usage = getattr(response, "usage", None)
                    if usage:
                        prompt_tokens = getattr(usage, "prompt_tokens", None)
                        total_tokens = getattr(usage, "total_tokens", None)
                        logger.info(
                            f"üßÆ Embedding tokens (batch {batch_num}): "
                            f"prompt={prompt_tokens}, total={total_tokens}"
                        )

                    logger.info(
                        f"‚úÖ –ë–∞—Ç—á {batch_num} –æ–±—Ä–∞–±–æ—Ç–∞–Ω: {len(batch_embeddings)} —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"
                    )
                    break  # –£—Å–ø–µ—à–Ω–æ - –≤—ã—Ö–æ–¥–∏–º –∏–∑ retry loop

                except Exception as e:
                    if attempt < max_retries - 1:
                        # Exponential backoff
                        wait_time = retry_delay * (2 ** attempt)
                        logger.warning(
                            f"‚ö†Ô∏è –ë–∞—Ç—á {batch_num} failed (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries}): {e}. "
                            f"–ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ {wait_time}—Å..."
                        )
                        time.sleep(wait_time)
                    else:
                        # –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –±–∞—Ç—á
                        logger.error(
                            f"‚ùå –ë–∞—Ç—á {batch_num} failed –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫: {e}. "
                            f"–ü—Ä–æ–ø—É—Å–∫–∞–µ–º –±–∞—Ç—á –∏ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º..."
                        )
                        failed_batches.append({
                            'batch_num': batch_num,
                            'start_idx': i,
                            'end_idx': i + len(batch),
                            'error': str(e)
                        })
                        # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Å—Ç—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–æ–≤
                        # (–∏–ª–∏ –º–æ–∂–Ω–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å - –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏)
                        break

        if failed_batches:
            logger.warning(
                f"‚ö†Ô∏è –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —Å –æ—à–∏–±–∫–∞–º–∏: {len(failed_batches)} –±–∞—Ç—á–µ–π –ø—Ä–æ–ø—É—â–µ–Ω–æ. "
                f"–£—Å–ø–µ—à–Ω–æ: {len(all_embeddings)}/{total_chunks} —á–∞–Ω–∫–æ–≤"
            )
            logger.warning(f"–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –±–∞—Ç—á–∏: {failed_batches}")
        else:
            logger.info(f"‚úÖ Generated {len(all_embeddings)} embeddings total")

        return all_embeddings
    
    def save_to_vector_db(
        self,
        embeddings: List[List[float]],
        chunks_metadata: List[Dict[str, Any]],
        cabinet_id: int,
        db: Session
    ) -> int:
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î.

        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã: –æ–±–Ω–æ–≤–ª—è–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∑–∞–ø–∏—Å–∏.
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —á–∞—Å—Ç–∏—á–Ω—É—é –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é: —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ç–æ–ª—å–∫–æ —É—Å–ø–µ—à–Ω—ã–µ —á–∞–Ω–∫–∏.

        Args:
            embeddings: –°–ø–∏—Å–æ–∫ –≤–µ–∫—Ç–æ—Ä–æ–≤
            chunks_metadata: –°–ø–∏—Å–æ–∫ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —á–∞–Ω–∫–∞
            cabinet_id: ID –∫–∞–±–∏–Ω–µ—Ç–∞
            db: –°–µ—Å—Å–∏—è –ë–î

        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
        """
        if len(embeddings) != len(chunks_metadata):
            logger.warning(
                f"‚ö†Ô∏è –ù–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –¥–ª–∏–Ω: —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ ({len(embeddings)}) != "
                f"–º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö ({len(chunks_metadata)}). "
                f"–°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —á–∞–Ω–∫–∏."
            )
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ —á–∞–Ω–∫–∏, –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö –µ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
            min_length = min(len(embeddings), len(chunks_metadata))
            embeddings = embeddings[:min_length]
            chunks_metadata = chunks_metadata[:min_length]
            logger.info(f"üìä –ë—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ {min_length} —á–∞–Ω–∫–æ–≤")
        
        saved_count = 0
        
        try:
            for embedding, chunk_meta in zip(embeddings, chunks_metadata):
                # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –∑–∞–ø–∏—Å—å
                existing_metadata = db.query(RAGMetadata).filter(
                    RAGMetadata.cabinet_id == cabinet_id,
                    RAGMetadata.source_table == chunk_meta['source_table'],
                    RAGMetadata.source_id == chunk_meta['source_id']
                ).first()
                
                if existing_metadata:
                    # –û–±–Ω–æ–≤–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –∑–∞–ø–∏—Å—å
                    existing_metadata.chunk_text = chunk_meta['chunk_text']
                    existing_metadata.chunk_type = chunk_meta['chunk_type']
                    existing_metadata.chunk_hash = self.calculate_chunk_hash(chunk_meta['chunk_text'])
                    existing_metadata.updated_at = datetime.now()

                    # –û–±–Ω–æ–≤–∏—Ç—å embedding
                    existing_embedding = db.query(RAGEmbedding).filter(
                        RAGEmbedding.metadata_id == existing_metadata.id
                    ).first()

                    if existing_embedding:
                        existing_embedding.embedding = embedding
                        existing_embedding.updated_at = datetime.now()
                    else:
                        # –°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π embedding (–µ—Å–ª–∏ –ø–æ –∫–∞–∫–æ–π-—Ç–æ –ø—Ä–∏—á–∏–Ω–µ –µ–≥–æ –Ω–µ—Ç)
                        new_embedding = RAGEmbedding(
                            embedding=embedding,
                            metadata_id=existing_metadata.id
                        )
                        db.add(new_embedding)

                else:
                    # –°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å
                    new_metadata = RAGMetadata(
                        cabinet_id=cabinet_id,
                        source_table=chunk_meta['source_table'],
                        source_id=chunk_meta['source_id'],
                        chunk_type=chunk_meta['chunk_type'],
                        chunk_text=chunk_meta['chunk_text'],
                        chunk_hash=self.calculate_chunk_hash(chunk_meta['chunk_text'])
                    )
                    db.add(new_metadata)
                    db.flush()  # –ü–æ–ª—É—á–∏—Ç—å ID –Ω–æ–≤–æ–π –∑–∞–ø–∏—Å–∏

                    new_embedding = RAGEmbedding(
                        embedding=embedding,
                        metadata_id=new_metadata.id
                    )
                    db.add(new_embedding)
                
                saved_count += 1
            
            # –ö–æ–º–º–∏—Ç –≤—Å–µ—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π
            db.commit()
            logger.info(f"‚úÖ Saved {saved_count} records to vector DB")
            
        except Exception as e:
            db.rollback()
            logger.error(f"‚ùå Error saving to vector DB: {e}")
            raise
        
        return saved_count
    
    async def index_cabinet(self, cabinet_id: int) -> Dict[str, Any]:
        """
        –ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –∫–∞–±–∏–Ω–µ—Ç–∞.
        
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ —Å —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º —Å—Ç–∞—Ç—É—Å–æ–º:
        1. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞
        2. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        3. –°–æ–∑–¥–∞–Ω–∏–µ —á–∞–Ω–∫–æ–≤
        4. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –ë–î
        
        Args:
            cabinet_id: ID –∫–∞–±–∏–Ω–µ—Ç–∞
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏:
            {
                'success': True/False,
                'cabinet_id': int,
                'total_chunks': int,
                'errors': List[str]
            }
        """
        result = {
            'success': False,
            'cabinet_id': cabinet_id,
            'total_chunks': 0,
            'errors': []
        }
        
        # –ü–æ–ª—É—á–∏—Ç—å —Å–µ—Å—Å–∏—é –ë–î
        db = RAGSessionLocal()
        index_status = None
        
        try:
            # 1. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
            index_status = db.query(RAGIndexStatus).filter(
                RAGIndexStatus.cabinet_id == cabinet_id
            ).first()
            
            if index_status and index_status.indexing_status == 'in_progress':
                logger.warning(
                    f"‚ö†Ô∏è –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∫–∞–±–∏–Ω–µ—Ç–∞ {cabinet_id} —É–∂–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è. –ü—Ä–æ–ø—É—Å–∫."
                )
                result['errors'].append("–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è —É–∂–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è")
                return result
            
            # 2. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å 'in_progress'
            if not index_status:
                index_status = RAGIndexStatus(
                    cabinet_id=cabinet_id,
                    indexing_status='in_progress'
                )
                db.add(index_status)
            else:
                index_status.indexing_status = 'in_progress'
                index_status.updated_at = datetime.now()
            
            db.commit()
            
            logger.info(f"üöÄ Starting indexing for cabinet {cabinet_id}")
            
            # 3. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
            try:
                data = await self.extract_data_from_main_db(cabinet_id)
            except Exception as e:
                logger.error(f"‚ùå Error extracting data: {e}")
                result['errors'].append(f"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
                raise
            
            # 4. –°–æ–∑–¥–∞–Ω–∏–µ —á–∞–Ω–∫–æ–≤
            try:
                chunks_metadata = self.create_chunks(data)
            except Exception as e:
                logger.error(f"‚ùå Error creating chunks: {e}")
                result['errors'].append(f"–°–æ–∑–¥–∞–Ω–∏–µ —á–∞–Ω–∫–æ–≤: {str(e)}")
                raise
            
            if not chunks_metadata:
                logger.warning(f"‚ö†Ô∏è No data to index for cabinet {cabinet_id}")
                index_status.indexing_status = 'completed'
                index_status.total_chunks = 0
                index_status.last_indexed_at = datetime.now()
                db.commit()
                result['success'] = True
                return result
            
            # 5. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            try:
                chunk_texts = [chunk['chunk_text'] for chunk in chunks_metadata]
                embeddings = self.generate_embeddings(chunk_texts)
            except Exception as e:
                logger.error(f"‚ùå Error generating embeddings: {e}")
                result['errors'].append(f"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {str(e)}")
                raise
            
            # 6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –ë–î
            try:
                saved_count = self.save_to_vector_db(
                    embeddings=embeddings,
                    chunks_metadata=chunks_metadata,
                    cabinet_id=cabinet_id,
                    db=db
                )
            except Exception as e:
                logger.error(f"‚ùå Error saving to DB: {e}")
                result['errors'].append(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –ë–î: {str(e)}")
                raise
            
            # 7. –û–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å 'completed'
            index_status.indexing_status = 'completed'
            index_status.last_indexed_at = datetime.now()
            index_status.total_chunks = saved_count
            index_status.updated_at = datetime.now()
            db.commit()
            
            result['success'] = True
            result['total_chunks'] = saved_count
            
            logger.info(
                f"‚úÖ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∫–∞–±–∏–Ω–µ—Ç–∞ {cabinet_id} –∑–∞–≤–µ—Ä—à–µ–Ω–∞: "
                f"{saved_count} —á–∞–Ω–∫–æ–≤ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ"
            )
            
        except Exception as e:
            # –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å 'failed'
            if index_status:
                index_status.indexing_status = 'failed'
                index_status.updated_at = datetime.now()
                db.commit()
            
            logger.error(f"‚ùå Error indexing cabinet {cabinet_id}: {e}")
            result['errors'].append(str(e))
            
        finally:
            db.close()
        
        return result
