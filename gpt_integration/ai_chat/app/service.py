"""
AI Chat Service - FastAPI application.

Provides REST API for conversational AI chat with Wildberries focus.
"""

import os
import logging
from typing import Optional
from pathlib import Path
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ –∫–æ—Ä–Ω–µ–≤–æ–≥–æ .env —Ñ–∞–π–ª–∞
# –í Docker –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã —á–µ—Ä–µ–∑ docker-compose.yml
env_file = Path(__file__).parent.parent.parent.parent / ".env"
if env_file.exists():
    load_dotenv(env_file)
else:
    # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ —Ç–µ–∫—É—â–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
    load_dotenv(override=False)

from fastapi import APIRouter, FastAPI, HTTPException, Header, Depends
from sqlalchemy.orm import Session
from openai import OpenAI

from .database import Base, engine, get_db
from .schemas import (
    ChatSendRequest,
    ChatSendResponse,
    ChatHistoryRequest,
    ChatHistoryResponse,
    ChatLimitsResponse,
    ResetLimitRequest,
    ResetLimitResponse,
    ChatStatsResponse,
)
from .crud import AIChatCRUD, DAILY_LIMIT
from .prompts import SYSTEM_PROMPT
from ..agent import run_agent
from ..tools.db_pool import init_pool as init_asyncpg_pool, close_pool as close_asyncpg_pool

# Import user model helper (correct path)
import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))
from gpt_integration.core.user_model import get_user_preferred_model_async

# RAG integration
try:
    from ..rag.prompt_enricher import enrich_prompt_with_rag, RAG_ENABLED
    from ..rag.utils import get_cabinet_id_for_user
except ImportError:
    # Fallback –¥–ª—è —Å–ª—É—á–∞—è, –∫–æ–≥–¥–∞ –ø–∞–ø–∫–∞ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è RAG (—Å –±–æ–ª—å—à–æ–π –±—É–∫–≤—ã)
    from ..RAG.prompt_enricher import enrich_prompt_with_rag, RAG_ENABLED
    from ..RAG.utils import get_cabinet_id_for_user


# ============================================================================
# Configuration
# ============================================================================

# Environment variables
API_SECRET_KEY = os.getenv("API_SECRET_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
_openai_base_url_raw = os.getenv("OPENAI_BASE_URL")
OPENAI_BASE_URL = None
if _openai_base_url_raw and _openai_base_url_raw.strip():
    _openai_base_url_clean = _openai_base_url_raw.strip()
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ URL –≤–∞–ª–∏–¥–Ω—ã–π (–Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å http:// –∏–ª–∏ https://)
    if _openai_base_url_clean.startswith(("http://", "https://")):
        OPENAI_BASE_URL = _openai_base_url_clean
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
OPENAI_TEMPERATURE = float(os.getenv("OPENAI_TEMPERATURE", "0.7"))
OPENAI_MAX_TOKENS = int(os.getenv("OPENAI_MAX_TOKENS", "1000"))
AI_CHAT_PORT = int(os.getenv("AI_CHAT_PORT", "9001"))

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


def _verify_api_key(x_api_key: Optional[str] = Header(None, alias="X-API-KEY")) -> None:
    """
    Verify API key from request headers.
    
    Args:
        x_api_key: API key from X-API-KEY header
        
    Raises:
        HTTPException: If API key is invalid or missing
    """
    if not API_SECRET_KEY:
        logger.error("‚ùå API_SECRET_KEY not configured on server")
        raise HTTPException(
            status_code=500,
            detail="API authentication not configured on server"
        )
    
    if not x_api_key or x_api_key != API_SECRET_KEY:
        logger.warning(f"‚õî Invalid API key attempt")
        raise HTTPException(
            status_code=403,
            detail="Invalid or missing API key"
        )


def _get_openai_client() -> OpenAI:
    """
    Create OpenAI client.
    
    Returns:
        OpenAI: Configured OpenAI client
        
    Raises:
        HTTPException: If OpenAI API key not configured
    """
    if not OPENAI_API_KEY:
        logger.error("‚ùå OPENAI_API_KEY not configured")
        raise HTTPException(
            status_code=500,
            detail="OpenAI API key not configured"
        )
    
    client_kwargs = {"api_key": OPENAI_API_KEY}
    if OPENAI_BASE_URL and OPENAI_BASE_URL.strip():
        client_kwargs["base_url"] = OPENAI_BASE_URL.strip()
    
    return OpenAI(**client_kwargs)


def _call_openai(
    messages: list,
    model: str = OPENAI_MODEL,
    max_tokens: int = OPENAI_MAX_TOKENS,
    temperature: float = OPENAI_TEMPERATURE
) -> tuple[str, int]:
    """
    Call OpenAI API with messages.
    
    Args:
        messages: List of message dicts for OpenAI API
        model: Model name (default from env)
        max_tokens: Maximum tokens in response
        temperature: Sampling temperature (0.0-2.0)
        
    Returns:
        tuple[str, int]: (response_text, tokens_used)
        
    Raises:
        HTTPException: If API call fails
    """
    try:
        client = _get_openai_client()
        
        logger.info(f"ü§ñ Calling OpenAI: model={model}, max_tokens={max_tokens}, temperature={temperature}, messages={len(messages)}")
        
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            max_tokens=max_tokens,
            temperature=temperature
        )
        
        response_text = response.choices[0].message.content
        tokens_used = response.usage.total_tokens
        
        logger.info(f"‚úÖ OpenAI response received: {len(response_text)} chars, {tokens_used} tokens")
        
        return (response_text, tokens_used)
        
    except Exception as e:
        logger.error(f"‚ùå OpenAI API error: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"AI service error: {str(e)}"
        )


router = APIRouter(tags=["ai-chat"])

@router.get("/health")
async def health_check():
    """
    Health check endpoint.
    
    Returns service status without authentication.
    """
    return {
        "status": "ok",
        "service": "ai_chat",
        "version": "1.0.0"
    }


@router.post("/send", response_model=ChatSendResponse)
async def send_message(
    request: ChatSendRequest,
    db: Session = Depends(get_db),
    _: None = Depends(_verify_api_key)
):
    """
    Send message to AI and get response.
    
    Rate limited to DAILY_LIMIT requests per day per user (0 = unlimited).
    """
    telegram_id = request.telegram_id
    message = request.message
    user_context = request.user_context
    
    logger.info(f"üì® Received chat request: telegram_id={telegram_id}, message_length={len(message)}, has_context={user_context is not None}")
    
    try:
        # Initialize CRUD
        crud = AIChatCRUD(db)
        
        # Check and update rate limit
        can_request, remaining = crud.check_and_update_limit(telegram_id)
        
        if not can_request:
            logger.warning(f"‚õî Rate limit exceeded for telegram_id={telegram_id}")
            raise HTTPException(
                status_code=429,
                detail={
                    "error": "Rate limit exceeded",
                    "message": (
                        f"–í—ã –∏—Å—á–µ—Ä–ø–∞–ª–∏ –¥–Ω–µ–≤–Ω–æ–π –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ ({DAILY_LIMIT}/–¥–µ–Ω—å). "
                        "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–≤—Ç—Ä–∞! üåÖ"
                    ),
                    "daily_limit": DAILY_LIMIT,
                    "requests_today": DAILY_LIMIT,
                    "requests_remaining": 0
                }
            )
        
        # Get recent context for AI
        context_messages = crud.get_recent_context(telegram_id, limit=5)
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º—É—é –º–æ–¥–µ–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_model = await get_user_preferred_model_async(telegram_id)
        logger.info(f"ü§ñ Using AI model for user {telegram_id}: {user_model}")
        
        # RAG: –ü–æ–ª—É—á–∏—Ç—å cabinet_id –∏ –æ–±–æ–≥–∞—Ç–∏—Ç—å –ø—Ä–æ–º–ø—Ç
        system_prompt = SYSTEM_PROMPT
        cabinet_id = None
        
        if RAG_ENABLED:
            try:
                cabinet_id = await get_cabinet_id_for_user(telegram_id)
                if cabinet_id:
                    system_prompt = await enrich_prompt_with_rag(
                        user_message=message,
                        cabinet_id=cabinet_id,
                        original_prompt=SYSTEM_PROMPT
                    )
                    logger.info(
                        f"‚úÖ Prompt enriched with RAG context for "
                        f"telegram_id={telegram_id}, cabinet_id={cabinet_id}"
                    )
                else:
                    logger.debug(
                        f"‚ö†Ô∏è Cabinet not found for telegram_id={telegram_id}, "
                        f"using original prompt"
                    )
            except Exception as e:
                logger.error(
                    f"‚ùå Error enriching prompt with RAG for "
                    f"telegram_id={telegram_id}: {e}",
                    exc_info=True
                )
                # Fallback –Ω–∞ –∏—Å—Ö–æ–¥–Ω—ã–π –ø—Ä–æ–º–ø—Ç
                system_prompt = SYSTEM_PROMPT
        
        # Build messages for OpenAI
        # –î–æ–±–∞–≤–ª—è–µ–º telegram_id –≤ system prompt, —á—Ç–æ–±—ã AI –∑–Ω–∞–ª –µ–≥–æ –∏ –Ω–µ –∑–∞–ø—Ä–∞—à–∏–≤–∞–ª —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        system_prompt_with_context = f"""{system_prompt}

**–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û - –ö–û–ù–¢–ï–ö–°–¢ –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø:**
- Telegram ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {telegram_id}
- ‚ùå –ù–ò–ö–û–ì–î–ê –Ω–µ –∑–∞–ø—Ä–∞—à–∏–≤–∞–π Telegram ID —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è - –æ–Ω —É–∂–µ –∏–∑–≤–µ—Å—Ç–µ–Ω!
- ‚úÖ –í–°–ï–ì–î–ê –∏—Å–ø–æ–ª—å–∑—É–π `telegram_id={telegram_id}` –ø—Ä–∏ –≤—ã–∑–æ–≤–µ –ª—é–±–æ–≥–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞.
- ‚úÖ –ù–∞–ø—Ä–∏–º–µ—Ä, –≤—ã–∑–æ–≤ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ `run_report` –¥–æ–ª–∂–µ–Ω –≤—ã–≥–ª—è–¥–µ—Ç—å —Ç–∞–∫: `run_report(report_name='top_products', params={{'telegram_id': {telegram_id}}})`. `telegram_id` –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤–Ω—É—Ç—Ä–∏ `params`.
- ‚úÖ –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –ø—Ä–æ —Å–≤–æ–∏ –¥–∞–Ω–Ω—ã–µ, —Å—Ä–∞–∑—É –∏—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã —Å `telegram_id={telegram_id}`, –ù–ï —Å–ø—Ä–∞—à–∏–≤–∞—è —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
        
        messages = [
            {"role": "system", "content": system_prompt_with_context},
            *context_messages,
        ]
        
        # Add user context if available
        if user_context:
            messages.append({
                "role": "system",
                "content": f"üìä –î–ê–ù–ù–´–ï –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø:\n{user_context}\n\n–ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç–∏ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤!"
            })
            logger.info(f"‚úÖ Added user context: {len(user_context)} chars")
        
        # Add user message
        messages.append({"role": "user", "content": message})
        
        # Stage 1: Call internal agent (LLM + tools in next stage)
        try:
            agent_result = await run_agent(messages, model=user_model)
            response_text = agent_result.get("final", "")
            tokens_used = agent_result.get("tokens_used", 0)
        except RuntimeError as e:
            # Handle regional restriction and other runtime errors
            error_msg = str(e)
            if "–Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –≤ –≤–∞—à–µ–º —Ä–µ–≥–∏–æ–Ω–µ" in error_msg or "unsupported_country" in error_msg.lower():
                logger.error(f"‚ùå Regional restriction error for telegram_id={telegram_id}: {error_msg}")
                raise HTTPException(
                    status_code=503,
                    detail={
                        "error": "OpenAI API unavailable",
                        "message": (
                            "‚ö†Ô∏è OpenAI API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –≤ –≤–∞—à–µ–º —Ä–µ–≥–∏–æ–Ω–µ.\n\n"
                            "–î–ª—è —Ä–µ—à–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º—ã –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π API endpoint:\n"
                            "1. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä–æ–∫—Å–∏-—Å–µ—Ä–≤–µ—Ä –¥–ª—è OpenAI API\n"
                            "2. –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä (Azure OpenAI, Anyscale –∏ –¥—Ä.)\n"
                            "3. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è OPENAI_BASE_URL —Å –∞–¥—Ä–µ—Å–æ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–≥–æ endpoint\n\n"
                            f"–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏: {error_msg}"
                        )
                    }
                )
            else:
                logger.error(f"‚ùå Runtime error for telegram_id={telegram_id}: {error_msg}")
                # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ, –µ—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ —É–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç "–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM"
                if "–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM:" in error_msg:
                    display_msg = error_msg
                else:
                    display_msg = f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM: {error_msg}"
                raise HTTPException(
                    status_code=500,
                    detail={
                        "error": "LLM request failed",
                        "message": display_msg
                    }
                )
        except Exception as e:
            logger.error(f"‚ùå Unexpected error for telegram_id={telegram_id}: {e}", exc_info=True)
            raise HTTPException(
                status_code=500,
                detail={
                    "error": "Internal server error",
                    "message": "‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –≤–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ –ø–æ–ø—ã—Ç–∫—É –ø–æ–∑–∂–µ."
                }
            )
        
        # Save to database
        crud.save_chat_request(
            telegram_id=telegram_id,
            user_id=None,  # TODO: Link with main database if needed
            message=message,
            response=response_text,
            tokens_used=tokens_used
        )
        
        logger.info(f"‚úÖ Chat request completed: telegram_id={telegram_id}, remaining={remaining}")
        
        return ChatSendResponse(
            response=response_text,
            remaining_requests=remaining,
            tokens_used=tokens_used
        )
    except HTTPException:
        # Re-raise HTTP exceptions (rate limit, etc.)
        raise
    except Exception as e:
        # Catch any other database or CRUD errors
        logger.error(f"‚ùå Database/CRUD error for telegram_id={telegram_id}: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail={
                "error": "Database error",
                "message": f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ä–∞–±–æ—Ç—ã —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö: {str(e)}"
            }
        )


@router.post("/history", response_model=ChatHistoryResponse)
async def get_history(
    request: ChatHistoryRequest,
    db: Session = Depends(get_db),
    _: None = Depends(_verify_api_key)
):
    """
    Get chat history for user with pagination.
    """
    telegram_id = request.telegram_id
    limit = request.limit
    offset = request.offset
    
    logger.info(f"üìú History request: telegram_id={telegram_id}, limit={limit}, offset={offset}")
    
    crud = AIChatCRUD(db)
    records, total = crud.get_chat_history(telegram_id, limit=limit, offset=offset)
    
    return ChatHistoryResponse(
        items=records,
        total=total,
        limit=limit,
        offset=offset
    )


@router.get("/limits/{telegram_id}", response_model=ChatLimitsResponse)
async def get_limits(
    telegram_id: int,
    db: Session = Depends(get_db),
    _: None = Depends(_verify_api_key)
):
    """
    Get current rate limits for user.
    
    Does NOT modify the request counter.
    """
    logger.info(f"üìä Limits check: telegram_id={telegram_id}")
    
    crud = AIChatCRUD(db)
    limits = crud.get_limits(telegram_id)
    
    return ChatLimitsResponse(
        telegram_id=telegram_id,
        **limits
    )


@router.post("/reset-limit", response_model=ResetLimitResponse)
async def reset_limit(
    request: ResetLimitRequest,
    db: Session = Depends(get_db),
    _: None = Depends(_verify_api_key)
):
    """
    Reset user's daily limit (admin function).
    """
    telegram_id = request.telegram_id
    
    logger.info(f"üîÑ Admin reset request: telegram_id={telegram_id}")
    
    crud = AIChatCRUD(db)
    success = crud.reset_user_limit(telegram_id)
    
    if success:
        return ResetLimitResponse(
            success=True,
            message=f"–õ–∏–º–∏—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {telegram_id} —É—Å–ø–µ—à–Ω–æ —Å–±—Ä–æ—à–µ–Ω"
        )
    else:
        return ResetLimitResponse(
            success=False,
            message=f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {telegram_id} –Ω–µ –Ω–∞–π–¥–µ–Ω"
        )


@router.get("/stats/{telegram_id}")
async def get_stats(
    telegram_id: int,
    days: int = 7,
    db: Session = Depends(get_db),
    _: None = Depends(_verify_api_key)
):
    """
    Get user statistics for the last N days.
    """
    logger.info(f"üìä Stats request: telegram_id={telegram_id}, days={days}")
    
    if days < 1 or days > 365:
        raise HTTPException(
            status_code=400,
            detail="Days parameter must be between 1 and 365"
        )
    
    crud = AIChatCRUD(db)
    stats = crud.get_user_stats(telegram_id, days=days)
    
    return {
        "telegram_id": telegram_id,
        **stats
    }


# ============================================================================
# Application Entry Point
# ============================================================================

def setup_ai_chat(app: FastAPI) -> None:
    """
    Register startup/shutdown handlers for AI chat components on the main app.
    """
    app.add_event_handler("startup", _startup_event)
    app.add_event_handler("shutdown", _shutdown_event)


# ============================================================================
# Internal lifecycle events for shared usage
# ============================================================================

_startup_registered = False


async def _startup_event():
    """Startup tasks for AI chat (idempotent)."""
    global _startup_registered
    if _startup_registered:
        return
    _startup_registered = True
    
    logger.info("üöÄ Starting AI Chat Service components...")
    
    if not OPENAI_API_KEY:
        logger.warning("‚ö†Ô∏è  OPENAI_API_KEY not configured!")
    else:
        logger.info("‚úÖ OpenAI API key configured")
    
    if not os.getenv("TESTING"):
        try:
            Base.metadata.create_all(bind=engine)
            logger.info("‚úÖ Database tables created/verified")
        except Exception as exc:
            logger.error("‚ùå Failed to create database tables: %s", exc, exc_info=True)
            # Don't raise - allow service to start even if DB init fails
            # The error will be caught when trying to use DB
            logger.warning("‚ö†Ô∏è  Service will continue, but database operations may fail")
    
    try:
        await init_asyncpg_pool()
        logger.info("‚úÖ asyncpg pool initialized (if Postgres configured)")
    except Exception as exc:
        logger.warning("‚ö†Ô∏è  asyncpg pool not initialized: %s", exc)
    
    # Initialize RAG database tables
    try:
        from ..RAG.database import init_rag_db
        init_rag_db()
        logger.info("‚úÖ RAG database tables created/verified")
    except Exception as exc:
        logger.error("‚ùå Failed to initialize RAG database: %s", exc, exc_info=True)
        # Don't raise - allow service to start even if RAG DB init fails
        logger.warning("‚ö†Ô∏è  Service will continue, but RAG features may not work")
    
    logger.info("üéØ AI Chat components ready")


async def _shutdown_event():
    """Shutdown tasks for AI chat."""
    logger.info("üëã Shutting down AI Chat components...")
    try:
        await close_asyncpg_pool()
    except Exception:
        pass


# ============================================================================
# Standalone application factory (legacy / manual usage)
# ============================================================================


def create_app() -> FastAPI:
    """Create a standalone FastAPI app for legacy/manual runs."""
    standalone_app = FastAPI(
        title="AI Chat Service",
        description="AI —á–∞—Ç-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –ø—Ä–æ–¥–∞–≤—Ü–æ–≤ Wildberries —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –∑–∞–ø—Ä–æ—Å–æ–≤",
        version="1.0.0",
    )
    setup_ai_chat(standalone_app)
    standalone_app.include_router(router, prefix="/v1/chat")
    standalone_app.add_api_route("/health", health_check, methods=["GET"], include_in_schema=False)
    return standalone_app


app = create_app()


if __name__ == "__main__":
    import uvicorn
    
    uvicorn.run(
        "gpt_integration.ai_chat.app.service:app",
        host="0.0.0.0",
        port=AI_CHAT_PORT,
        reload=True
    )
