import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º –±–æ—Ç–∞
sys.path.insert(0, str(Path(__file__).parent.parent))

import logging
from aiogram import Router, F
from aiogram.filters import Command
from aiogram.types import Message, CallbackQuery
from aiogram.fsm.context import FSMContext

from core.states import GPTStates
from utils.formatters import (
    safe_send_message,
    safe_edit_message,
    handle_telegram_errors,
    escape_markdown_v2,
    split_telegram_message,
)
from gpt_integration.gpt_client import GPTClient

logger = logging.getLogger(__name__)

router = Router()


def _format_and_split(text: str) -> list[str]:
    md = escape_markdown_v2(text)
    return split_telegram_message(md)


@router.message(Command("gpt"))
@handle_telegram_errors
async def cmd_gpt(message: Message, state: FSMContext):
    """–í—Ö–æ–¥ –≤ —Ä–µ–∂–∏–º GPT-—á–∞—Ç–∞ –ø–æ –∫–æ–º–∞–Ω–¥–µ /gpt"""
    await state.set_state(GPTStates.gpt_chat)
    await safe_send_message(
        message,
        "ü§ñ –í—ã –≤–æ—à–ª–∏ –≤ —Ä–µ–∂–∏–º AI-—á–∞—Ç.\n–ù–∞–ø–∏—à–∏—Ç–µ –≤–æ–ø—Ä–æ—Å –¥–ª—è GPT.\n\n–ß—Ç–æ–±—ã –≤—ã–π—Ç–∏, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—É /exit",
        user_id=message.from_user.id,
    )


@router.callback_query(F.data == "ai_chat")
@handle_telegram_errors
async def cb_ai_chat(callback: CallbackQuery, state: FSMContext):
    """–í—Ö–æ–¥ –≤ —Ä–µ–∂–∏–º GPT-—á–∞—Ç–∞ –ø–æ –∫–Ω–æ–ø–∫–µ 'AI-—á–∞—Ç'"""
    await state.set_state(GPTStates.gpt_chat)
    await safe_edit_message(
        callback,
        "ü§ñ –†–µ–∂–∏–º AI-—á–∞—Ç –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω.\n–ù–∞–ø–∏—à–∏—Ç–µ –≤–æ–ø—Ä–æ—Å –¥–ª—è GPT.\n\n–ß—Ç–æ–±—ã –≤—ã–π—Ç–∏, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—É /exit",
        user_id=callback.from_user.id,
    )


@router.message(Command("exit"))
@handle_telegram_errors
async def cmd_exit(message: Message, state: FSMContext):
    """–í—ã—Ö–æ–¥ –∏–∑ —Ä–µ–∂–∏–º–∞ GPT-—á–∞—Ç–∞"""
    await state.clear()
    await safe_send_message(
        message,
        "‚úÖ –í—ã –≤—ã—à–ª–∏ –∏–∑ —Ä–µ–∂–∏–º–∞ AI-—á–∞—Ç. –í–æ–∑–≤—Ä–∞—â–∞–π—Ç–µ—Å—å, –∫–æ–≥–¥–∞ –±—É–¥—É—Ç –≤–æ–ø—Ä–æ—Å—ã!",
        user_id=message.from_user.id,
    )


@router.message(GPTStates.gpt_chat)
@handle_telegram_errors
async def gpt_chat_message(message: Message, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ GPT-—á–∞—Ç–µ"""
    user_text = (message.text or "").strip()
    if not user_text:
        await safe_send_message(
            message,
            "‚úçÔ∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å.",
            user_id=message.from_user.id,
        )
        return

    # –í—ã–∑—ã–≤–∞–µ–º LLM —á–µ—Ä–µ–∑ –∫–ª–∏–µ–Ω—Ç–∞
    try:
        client = GPTClient.from_env()
        messages = [{"role": "user", "content": user_text}]
        llm_text = client.complete_messages(messages)
    except Exception as e:
        logger.exception("LLM –≤—ã–∑–æ–≤ –∑–∞–≤–µ—Ä—à–∏–ª—Å—è –æ—à–∏–±–∫–æ–π")
        await safe_send_message(
            message,
            f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM: {e}",
            user_id=message.from_user.id,
        )
        return

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ MarkdownV2 –∏ –æ—Ç–ø—Ä–∞–≤–∫–∞ –ø–æ —á–∞—Å—Ç—è–º
    chunks = _format_and_split(llm_text)
    if not chunks:
        chunks = ["(–ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç)"]

    for chunk in chunks:
        await safe_send_message(
            message,
            chunk,
            user_id=message.from_user.id,
            parse_mode="MarkdownV2",
        )