# ü§ñ –í—ã–±–æ—Ä AI –º–æ–¥–µ–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º

## üìã –û–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏

–†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –≤—ã–±–æ—Ä–∞ AI –º–æ–¥–µ–ª–∏ (GPT-4o –∏–ª–∏ Claude Sonnet 3.5) –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ. –í—ã–±—Ä–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –¥–ª—è:
- AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ (RAG)
- –ê–Ω–∞–ª–∏—Ç–∏–∫–∏ –ø—Ä–æ–¥–∞–∂
- –ì–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞

## üéØ –¶–µ–ª–∏

1. –£–±—Ä–∞—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é `COMET_TEXT_MODEL` –∏–∑ `.env`
2. –î–æ–±–∞–≤–∏—Ç—å –ø–æ–ª–µ `preferred_ai_model` –≤ —Ç–∞–±–ª–∏—Ü—É `users`
3. –°–æ–∑–¥–∞—Ç—å UI –¥–ª—è –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö –±–æ—Ç–∞
4. –û–±–Ω–æ–≤–∏—Ç—å GPT —Å–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–º–∏ –º–æ–¥–µ–ª—è–º–∏
5. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å `gpt-4o` –∫–∞–∫ –º–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

## üèó –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Ä–µ—à–µ–Ω–∏—è

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Telegram Bot   ‚îÇ
‚îÇ   –ù–∞—Å—Ç—Ä–æ–π–∫–∏     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Backend API   ‚îÇ
‚îÇ Update user     ‚îÇ
‚îÇ preferred_model ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   PostgreSQL    ‚îÇ
‚îÇ users.preferred ‚îÇ
‚îÇ   _ai_model     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  GPT Service    ‚îÇ
‚îÇ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç      ‚îÇ
‚îÇ –º–æ–¥–µ–ª—å —é–∑–µ—Ä–∞    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìù –≠—Ç–∞–ø 1: –ú–∏–≥—Ä–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö

### 1.1 –°–æ–∑–¥–∞–Ω–∏–µ –º–∏–≥—Ä–∞—Ü–∏–∏

–°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—É—é –º–∏–≥—Ä–∞—Ü–∏—é Alembic:

```bash
cd server
alembic revision -m "add_preferred_ai_model_to_users"
```

### 1.2 –°–æ–¥–µ—Ä–∂–∏–º–æ–µ –º–∏–≥—Ä–∞—Ü–∏–∏

–§–∞–π–ª: `server/alembic/versions/XXXX_add_preferred_ai_model_to_users.py`


```python
"""add preferred_ai_model to users

Revision ID: XXXX
Revises: YYYY
Create Date: 2026-02-09

"""
from alembic import op
import sqlalchemy as sa

revision = 'XXXX'
down_revision = 'YYYY'
branch_labels = None
depends_on = None

def upgrade():
    # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É preferred_ai_model
    op.add_column('users', 
        sa.Column('preferred_ai_model', 
                  sa.String(50), 
                  nullable=False, 
                  server_default='gpt-4o')
    )
    
    # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
    op.create_index('idx_users_preferred_ai_model', 
                    'users', 
                    ['preferred_ai_model'])

def downgrade():
    op.drop_index('idx_users_preferred_ai_model', table_name='users')
    op.drop_column('users', 'preferred_ai_model')
```

### 1.3 –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –º–∏–≥—Ä–∞—Ü–∏–∏

```bash
cd server
alembic upgrade head
```

---

## üìù –≠—Ç–∞–ø 2: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ User

### 2.1 –û–±–Ω–æ–≤–∏—Ç—å –º–æ–¥–µ–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

–§–∞–π–ª: `server/app/features/wb_api/models.py` (–∏–ª–∏ –≥–¥–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –º–æ–¥–µ–ª—å User)

```python
from sqlalchemy import Column, Integer, String, DateTime, Boolean
from sqlalchemy.sql import func

class User(Base):
    __tablename__ = "users"
    
    id = Column(Integer, primary_key=True, index=True)
    telegram_id = Column(Integer, unique=True, index=True, nullable=False)
    username = Column(String, nullable=True)
    first_name = Column(String, nullable=True)
    last_name = Column(String, nullable=True)
    
    # –ù–æ–≤–æ–µ –ø–æ–ª–µ –¥–ª—è –≤—ã–±–æ—Ä–∞ AI –º–æ–¥–µ–ª–∏
    preferred_ai_model = Column(
        String(50), 
        nullable=False, 
        default='gpt-4o',
        server_default='gpt-4o'
    )
    
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    updated_at = Column(DateTime(timezone=True), onupdate=func.now())
```

### 2.2 –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏

–°–æ–∑–¥–∞—Ç—å enum –¥–ª—è –º–æ–¥–µ–ª–µ–π:

–§–∞–π–ª: `server/app/core/ai_models.py`

```python
from enum import Enum

class AIModel(str, Enum):
    """–î–æ—Å—Ç—É–ø–Ω—ã–µ AI –º–æ–¥–µ–ª–∏ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"""
    GPT_4O = "gpt-4o"
    CLAUDE_SONNET_35 = "claude-sonnet-3.5"
    
    @classmethod
    def get_display_name(cls, model: str) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å —á–∏—Ç–∞–µ–º–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        names = {
            cls.GPT_4O: "GPT-4o (OpenAI)",
            cls.CLAUDE_SONNET_35: "Claude Sonnet 3.5 (Anthropic)"
        }
        return names.get(model, model)
    
    @classmethod
    def get_default(cls) -> str:
        """–ú–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é"""
        return cls.GPT_4O
```

---

## üìù –≠—Ç–∞–ø 3: Backend API endpoints

### 3.1 –°–æ–∑–¥–∞—Ç—å —Å—Ö–µ–º—ã Pydantic

–§–∞–π–ª: `server/app/features/bot_api/schemas.py`

```python
from pydantic import BaseModel, Field
from typing import Optional

class UserSettingsUpdate(BaseModel):
    """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    preferred_ai_model: Optional[str] = Field(
        None, 
        description="–ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º–∞—è AI –º–æ–¥–µ–ª—å"
    )

class UserSettingsResponse(BaseModel):
    """–û—Ç–≤–µ—Ç —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    telegram_id: int
    preferred_ai_model: str
    
    class Config:
        from_attributes = True

class AIModelsListResponse(BaseModel):
    """–°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö AI –º–æ–¥–µ–ª–µ–π"""
    models: list[dict]
    default_model: str
```

### 3.2 –î–æ–±–∞–≤–∏—Ç—å endpoints

–§–∞–π–ª: `server/app/features/bot_api/routes.py`


```python
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from app.core.database import get_db
from app.core.ai_models import AIModel
from .schemas import UserSettingsUpdate, UserSettingsResponse, AIModelsListResponse

router = APIRouter(prefix="/api/v1/bot", tags=["bot"])

@router.get("/ai-models", response_model=AIModelsListResponse)
async def get_available_ai_models():
    """
    –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö AI –º–æ–¥–µ–ª–µ–π
    """
    models = [
        {
            "id": AIModel.GPT_4O,
            "name": AIModel.get_display_name(AIModel.GPT_4O),
            "provider": "OpenAI",
            "description": "–ë—ã—Å—Ç—Ä–∞—è –∏ —Ç–æ—á–Ω–∞—è –º–æ–¥–µ–ª—å –æ—Ç OpenAI"
        },
        {
            "id": AIModel.CLAUDE_SONNET_35,
            "name": AIModel.get_display_name(AIModel.CLAUDE_SONNET_35),
            "provider": "Anthropic",
            "description": "–ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –º–æ–¥–µ–ª—å —Å –≥–ª—É–±–æ–∫–∏–º –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"
        }
    ]
    
    return {
        "models": models,
        "default_model": AIModel.get_default()
    }

@router.get("/settings", response_model=UserSettingsResponse)
async def get_user_settings(
    telegram_id: int,
    db: Session = Depends(get_db)
):
    """
    –ü–æ–ª—É—á–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    """
    user = db.query(User).filter(User.telegram_id == telegram_id).first()
    
    if not user:
        raise HTTPException(status_code=404, detail="User not found")
    
    return {
        "telegram_id": user.telegram_id,
        "preferred_ai_model": user.preferred_ai_model
    }

@router.patch("/settings", response_model=UserSettingsResponse)
async def update_user_settings(
    telegram_id: int,
    settings: UserSettingsUpdate,
    db: Session = Depends(get_db)
):
    """
    –û–±–Ω–æ–≤–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    """
    user = db.query(User).filter(User.telegram_id == telegram_id).first()
    
    if not user:
        raise HTTPException(status_code=404, detail="User not found")
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
    if settings.preferred_ai_model:
        if settings.preferred_ai_model not in [AIModel.GPT_4O, AIModel.CLAUDE_SONNET_35]:
            raise HTTPException(
                status_code=400, 
                detail=f"Invalid AI model. Available: {[m.value for m in AIModel]}"
            )
        user.preferred_ai_model = settings.preferred_ai_model
    
    db.commit()
    db.refresh(user)
    
    return {
        "telegram_id": user.telegram_id,
        "preferred_ai_model": user.preferred_ai_model
    }
```

---

## üìù –≠—Ç–∞–ø 4: Telegram Bot - UI –¥–ª—è –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏

### 4.1 –û–±–Ω–æ–≤–∏—Ç—å –∫–ª–∞–≤–∏–∞—Ç—É—Ä—ã

–§–∞–π–ª: `bot/keyboards/keyboards.py`

```python
from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton

def get_settings_keyboard() -> InlineKeyboardMarkup:
    """–ö–ª–∞–≤–∏–∞—Ç—É—Ä–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫"""
    keyboard = InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text="ü§ñ –í—ã–±–æ—Ä AI –º–æ–¥–µ–ª–∏", callback_data="settings_ai_model")],
        [InlineKeyboardButton(text="üîî –£–≤–µ–¥–æ–º–ª–µ–Ω–∏—è", callback_data="settings_notifications")],
        [InlineKeyboardButton(text="‚¨ÖÔ∏è –ù–∞–∑–∞–¥", callback_data="back_to_menu")]
    ])
    return keyboard

def get_ai_model_selection_keyboard(current_model: str) -> InlineKeyboardMarkup:
    """–ö–ª–∞–≤–∏–∞—Ç—É—Ä–∞ –≤—ã–±–æ—Ä–∞ AI –º–æ–¥–µ–ª–∏"""
    keyboard = InlineKeyboardMarkup(inline_keyboard=[
        [
            InlineKeyboardButton(
                text="‚úÖ GPT-4o" if current_model == "gpt-4o" else "GPT-4o",
                callback_data="ai_model_gpt-4o"
            )
        ],
        [
            InlineKeyboardButton(
                text="‚úÖ Claude Sonnet 3.5" if current_model == "claude-sonnet-3.5" else "Claude Sonnet 3.5",
                callback_data="ai_model_claude-sonnet-3.5"
            )
        ],
        [InlineKeyboardButton(text="‚¨ÖÔ∏è –ù–∞–∑–∞–¥ –∫ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º", callback_data="back_to_settings")]
    ])
    return keyboard
```

### 4.2 –°–æ–∑–¥–∞—Ç—å handler –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–µ–∫

–§–∞–π–ª: `bot/handlers/settings.py`


```python
from aiogram import Router, F
from aiogram.types import CallbackQuery, Message
from aiogram.filters import Command
from bot.api.client import BotAPIClient
from bot.keyboards.keyboards import get_settings_keyboard, get_ai_model_selection_keyboard

router = Router()

@router.message(Command("settings"))
async def cmd_settings(message: Message):
    """–ö–æ–º–∞–Ω–¥–∞ /settings - –æ—Ç–∫—Ä—ã—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏"""
    await message.answer(
        "‚öôÔ∏è <b>–ù–∞—Å—Ç—Ä–æ–π–∫–∏</b>\n\n"
        "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–∞–∑–¥–µ–ª –Ω–∞—Å—Ç—Ä–æ–µ–∫:",
        reply_markup=get_settings_keyboard()
    )

@router.callback_query(F.data == "settings_ai_model")
async def show_ai_model_selection(callback: CallbackQuery):
    """–ü–æ–∫–∞–∑–∞—Ç—å –≤—ã–±–æ—Ä AI –º–æ–¥–µ–ª–∏"""
    client = BotAPIClient()
    
    # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    settings = await client.get_user_settings(callback.from_user.id)
    current_model = settings.get("preferred_ai_model", "gpt-4o")
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
    models_data = await client.get_available_ai_models()
    
    text = (
        "ü§ñ <b>–í—ã–±–æ—Ä AI –º–æ–¥–µ–ª–∏</b>\n\n"
        f"–¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å: <b>{get_model_display_name(current_model)}</b>\n\n"
        "–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:\n\n"
    )
    
    for model in models_data["models"]:
        text += f"‚Ä¢ <b>{model['name']}</b>\n"
        text += f"  {model['description']}\n\n"
    
    text += "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏:"
    
    await callback.message.edit_text(
        text,
        reply_markup=get_ai_model_selection_keyboard(current_model)
    )
    await callback.answer()

@router.callback_query(F.data.startswith("ai_model_"))
async def select_ai_model(callback: CallbackQuery):
    """–í—ã–±—Ä–∞—Ç—å AI –º–æ–¥–µ–ª—å"""
    model_id = callback.data.replace("ai_model_", "")
    client = BotAPIClient()
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    await client.update_user_settings(
        telegram_id=callback.from_user.id,
        preferred_ai_model=model_id
    )
    
    model_name = get_model_display_name(model_id)
    
    await callback.answer(
        f"‚úÖ –ú–æ–¥–µ–ª—å {model_name} –≤—ã–±—Ä–∞–Ω–∞!",
        show_alert=True
    )
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É
    await callback.message.edit_reply_markup(
        reply_markup=get_ai_model_selection_keyboard(model_id)
    )

@router.callback_query(F.data == "back_to_settings")
async def back_to_settings(callback: CallbackQuery):
    """–í–µ—Ä–Ω—É—Ç—å—Å—è –∫ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º"""
    await callback.message.edit_text(
        "‚öôÔ∏è <b>–ù–∞—Å—Ç—Ä–æ–π–∫–∏</b>\n\n"
        "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–∞–∑–¥–µ–ª –Ω–∞—Å—Ç—Ä–æ–µ–∫:",
        reply_markup=get_settings_keyboard()
    )
    await callback.answer()

def get_model_display_name(model_id: str) -> str:
    """–ü–æ–ª—É—á–∏—Ç—å —á–∏—Ç–∞–µ–º–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
    names = {
        "gpt-4o": "GPT-4o (OpenAI)",
        "claude-sonnet-3.5": "Claude Sonnet 3.5 (Anthropic)"
    }
    return names.get(model_id, model_id)
```

### 4.3 –û–±–Ω–æ–≤–∏—Ç—å API –∫–ª–∏–µ–Ω—Ç –±–æ—Ç–∞

–§–∞–π–ª: `bot/api/client.py`

```python
class BotAPIClient:
    # ... —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–¥ ...
    
    async def get_available_ai_models(self) -> dict:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö AI –º–æ–¥–µ–ª–µ–π"""
        response = await self._make_request("GET", "/ai-models")
        return response
    
    async def get_user_settings(self, telegram_id: int) -> dict:
        """–ü–æ–ª—É—á–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        response = await self._make_request(
            "GET", 
            "/settings",
            params={"telegram_id": telegram_id}
        )
        return response
    
    async def update_user_settings(
        self, 
        telegram_id: int, 
        preferred_ai_model: str = None
    ) -> dict:
        """–û–±–Ω–æ–≤–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        data = {}
        if preferred_ai_model:
            data["preferred_ai_model"] = preferred_ai_model
        
        response = await self._make_request(
            "PATCH",
            "/settings",
            params={"telegram_id": telegram_id},
            json=data
        )
        return response
```

### 4.4 –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å router

–§–∞–π–ª: `bot/__main__.py`

```python
from bot.handlers import settings

# ... —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–¥ ...

# –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è handlers
dp.include_router(settings.router)
```

---

## üìù –≠—Ç–∞–ø 5: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ GPT Service

### 5.1 –û–±–Ω–æ–≤–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é

–§–∞–π–ª: `gpt_integration/core/config.py`


```python
import os
from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    # OpenAI
    OPENAI_API_KEY: str = os.getenv("OPENAI_API_KEY", "")
    OPENAI_BASE_URL: str = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
    
    # Anthropic (Claude)
    ANTHROPIC_API_KEY: str = os.getenv("ANTHROPIC_API_KEY", "")
    
    # –ú–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (–µ—Å–ª–∏ —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–µ —É–∫–∞–∑–∞–Ω–∞)
    DEFAULT_AI_MODEL: str = "gpt-4o"
    
    # –£–¥–∞–ª–∏—Ç—å COMET_TEXT_MODEL - –±–æ–ª—å—à–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
    # COMET_TEXT_MODEL: str = "gpt-4.1"  # DEPRECATED
    
    class Config:
        env_file = ".env"

settings = Settings()
```

### 5.2 –°–æ–∑–¥–∞—Ç—å —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π LLM –∫–ª–∏–µ–Ω—Ç

–§–∞–π–ª: `gpt_integration/core/llm_client.py`

```python
from typing import Optional, List, Dict
import httpx
from openai import AsyncOpenAI
from anthropic import AsyncAnthropic
from .config import settings

class UniversalLLMClient:
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ä–∞–∑–Ω—ã–º–∏ LLM"""
    
    def __init__(self):
        self.openai_client = AsyncOpenAI(
            api_key=settings.OPENAI_API_KEY,
            base_url=settings.OPENAI_BASE_URL
        )
        self.anthropic_client = AsyncAnthropic(
            api_key=settings.ANTHROPIC_API_KEY
        ) if settings.ANTHROPIC_API_KEY else None
    
    async def chat_completion(
        self,
        model: str,
        messages: List[Dict[str, str]],
        temperature: float = 0.7,
        max_tokens: int = 2000
    ) -> str:
        """
        –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è chat completion
        
        Args:
            model: ID –º–æ–¥–µ–ª–∏ (gpt-4o, claude-sonnet-3.5)
            messages: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            max_tokens: –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤
        
        Returns:
            –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        if model.startswith("gpt"):
            return await self._openai_completion(model, messages, temperature, max_tokens)
        elif model.startswith("claude"):
            return await self._anthropic_completion(model, messages, temperature, max_tokens)
        else:
            raise ValueError(f"Unsupported model: {model}")
    
    async def _openai_completion(
        self,
        model: str,
        messages: List[Dict[str, str]],
        temperature: float,
        max_tokens: int
    ) -> str:
        """OpenAI completion"""
        response = await self.openai_client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens
        )
        return response.choices[0].message.content
    
    async def _anthropic_completion(
        self,
        model: str,
        messages: List[Dict[str, str]],
        temperature: float,
        max_tokens: int
    ) -> str:
        """Anthropic (Claude) completion"""
        if not self.anthropic_client:
            raise ValueError("Anthropic API key not configured")
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ñ–æ—Ä–º–∞—Ç —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è Claude
        system_message = None
        claude_messages = []
        
        for msg in messages:
            if msg["role"] == "system":
                system_message = msg["content"]
            else:
                claude_messages.append({
                    "role": msg["role"],
                    "content": msg["content"]
                })
        
        response = await self.anthropic_client.messages.create(
            model=model,
            system=system_message,
            messages=claude_messages,
            temperature=temperature,
            max_tokens=max_tokens
        )
        
        return response.content[0].text

# Singleton instance
llm_client = UniversalLLMClient()
```

### 5.3 –û–±–Ω–æ–≤–∏—Ç—å AI Chat —Å–µ—Ä–≤–∏—Å

–§–∞–π–ª: `gpt_integration/ai_chat/service.py`

```python
from gpt_integration.core.llm_client import llm_client
from gpt_integration.core.config import settings

class AIChatService:
    # ... —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–¥ ...
    
    async def get_user_model(self, telegram_id: int) -> str:
        """
        –ü–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º—É—é –º–æ–¥–µ–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ –ë–î
        
        Args:
            telegram_id: Telegram ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        
        Returns:
            ID –º–æ–¥–µ–ª–∏ (gpt-4o, claude-sonnet-3.5)
        """
        user = self.db.query(User).filter(
            User.telegram_id == telegram_id
        ).first()
        
        if user and user.preferred_ai_model:
            return user.preferred_ai_model
        
        return settings.DEFAULT_AI_MODEL
    
    async def send_message(
        self,
        telegram_id: int,
        message: str,
        context: Optional[str] = None
    ) -> dict:
        """–û—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ AI —á–∞—Ç"""
        
        # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_model = await self.get_user_model(telegram_id)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç—ã
        if not await self.check_limits(telegram_id):
            return {
                "success": False,
                "error": "Daily limit exceeded"
            }
        
        # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é
        history = await self.get_history(telegram_id, limit=10)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º messages
        messages = [
            {"role": "system", "content": self.system_prompt}
        ]
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é
        for msg in history:
            messages.append({"role": "user", "content": msg.user_message})
            messages.append({"role": "assistant", "content": msg.assistant_response})
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        if context:
            messages.append({"role": "user", "content": f"–ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}\n\n–í–æ–ø—Ä–æ—Å: {message}"})
        else:
            messages.append({"role": "user", "content": message})
        
        # –í—ã–∑—ã–≤–∞–µ–º LLM —Å –º–æ–¥–µ–ª—å—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        response_text = await llm_client.chat_completion(
            model=user_model,
            messages=messages,
            temperature=0.7,
            max_tokens=2000
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
        await self.save_to_history(telegram_id, message, response_text)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ª–∏–º–∏—Ç—ã
        await self.increment_usage(telegram_id)
        
        return {
            "success": True,
            "response": response_text,
            "model_used": user_model,
            "remaining_requests": await self.get_remaining_requests(telegram_id)
        }
```

### 5.4 –û–±–Ω–æ–≤–∏—Ç—å Analysis —Å–µ—Ä–≤–∏—Å

–§–∞–π–ª: `gpt_integration/analysis/service.py`


```python
from gpt_integration.core.llm_client import llm_client
from gpt_integration.core.config import settings

class AnalysisService:
    # ... —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–¥ ...
    
    async def get_user_model(self, telegram_id: int) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º—É—é –º–æ–¥–µ–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        user = self.db.query(User).filter(
            User.telegram_id == telegram_id
        ).first()
        
        if user and user.preferred_ai_model:
            return user.preferred_ai_model
        
        return settings.DEFAULT_AI_MODEL
    
    async def analyze_sales(
        self,
        telegram_id: int,
        period: str = "7d"
    ) -> dict:
        """–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–¥–∞–∂ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–æ–¥–µ–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        
        # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_model = await self.get_user_model(telegram_id)
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        sales_data = await self.fetch_sales_data(telegram_id, period)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç
        messages = [
            {"role": "system", "content": self.analysis_system_prompt},
            {"role": "user", "content": self.format_analysis_prompt(sales_data)}
        ]
        
        # –í—ã–∑—ã–≤–∞–µ–º LLM —Å –º–æ–¥–µ–ª—å—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        analysis_text = await llm_client.chat_completion(
            model=user_model,
            messages=messages,
            temperature=0.3,  # –ë–æ–ª–µ–µ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
            max_tokens=3000
        )
        
        return {
            "success": True,
            "analysis": analysis_text,
            "model_used": user_model,
            "period": period
        }
```

---

## üìù –≠—Ç–∞–ø 6: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ .env —Ñ–∞–π–ª–æ–≤

### 6.1 –û–±–Ω–æ–≤–∏—Ç—å .env

```env
# OpenAI
OPENAI_API_KEY=sk-...
OPENAI_BASE_URL=https://api.openai.com/v1

# Anthropic (Claude)
ANTHROPIC_API_KEY=sk-ant-...

# –ú–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
DEFAULT_AI_MODEL=gpt-4o

# DEPRECATED - –±–æ–ª—å—à–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
# COMET_TEXT_MODEL=gpt-4.1
```

### 6.2 –û–±–Ω–æ–≤–∏—Ç—å env_example.txt

```env
# AI Models Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_BASE_URL=https://api.openai.com/v1
ANTHROPIC_API_KEY=your_anthropic_api_key_here
DEFAULT_AI_MODEL=gpt-4o
```

---

## üìù –≠—Ç–∞–ø 7: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

### 7.1 Unit —Ç–µ—Å—Ç—ã

–§–∞–π–ª: `server/tests/unit/test_ai_model_selection.py`

```python
import pytest
from app.core.ai_models import AIModel

def test_ai_model_enum():
    """–¢–µ—Å—Ç enum –º–æ–¥–µ–ª–µ–π"""
    assert AIModel.GPT_4O == "gpt-4o"
    assert AIModel.CLAUDE_SONNET_35 == "claude-sonnet-3.5"
    assert AIModel.get_default() == "gpt-4o"

def test_ai_model_display_names():
    """–¢–µ—Å—Ç –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏–π"""
    assert "GPT-4o" in AIModel.get_display_name(AIModel.GPT_4O)
    assert "Claude" in AIModel.get_display_name(AIModel.CLAUDE_SONNET_35)

@pytest.mark.asyncio
async def test_update_user_model(client, test_user):
    """–¢–µ—Å—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    response = await client.patch(
        f"/api/v1/bot/settings?telegram_id={test_user.telegram_id}",
        json={"preferred_ai_model": "claude-sonnet-3.5"}
    )
    
    assert response.status_code == 200
    data = response.json()
    assert data["preferred_ai_model"] == "claude-sonnet-3.5"

@pytest.mark.asyncio
async def test_invalid_model(client, test_user):
    """–¢–µ—Å—Ç –Ω–µ–≤–∞–ª–∏–¥–Ω–æ–π –º–æ–¥–µ–ª–∏"""
    response = await client.patch(
        f"/api/v1/bot/settings?telegram_id={test_user.telegram_id}",
        json={"preferred_ai_model": "invalid-model"}
    )
    
    assert response.status_code == 400
```

### 7.2 Integration —Ç–µ—Å—Ç—ã

–§–∞–π–ª: `tests/integration/test_ai_chat_with_models.py`

```python
import pytest

@pytest.mark.asyncio
async def test_ai_chat_with_gpt(bot_client, test_user):
    """–¢–µ—Å—Ç AI —á–∞—Ç–∞ —Å GPT-4o"""
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å
    await bot_client.update_user_settings(
        test_user.telegram_id,
        preferred_ai_model="gpt-4o"
    )
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
    response = await bot_client.send_ai_message(
        test_user.telegram_id,
        "–ü—Ä–∏–≤–µ—Ç!"
    )
    
    assert response["success"] is True
    assert response["model_used"] == "gpt-4o"
    assert len(response["response"]) > 0

@pytest.mark.asyncio
async def test_ai_chat_with_claude(bot_client, test_user):
    """–¢–µ—Å—Ç AI —á–∞—Ç–∞ —Å Claude"""
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å
    await bot_client.update_user_settings(
        test_user.telegram_id,
        preferred_ai_model="claude-sonnet-3.5"
    )
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
    response = await bot_client.send_ai_message(
        test_user.telegram_id,
        "–ü—Ä–∏–≤–µ—Ç!"
    )
    
    assert response["success"] is True
    assert response["model_used"] == "claude-sonnet-3.5"
    assert len(response["response"]) > 0
```

### 7.3 –†—É—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

1. **–ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–≥—Ä–∞—Ü–∏–∏:**
```bash
cd server
alembic upgrade head
psql -U user -d wb_assist_db -c "SELECT telegram_id, preferred_ai_model FROM users LIMIT 5;"
```

2. **–ü—Ä–æ–≤–µ—Ä–∫–∞ API:**
```bash
# –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π
curl http://localhost:8002/api/v1/bot/ai-models

# –ü–æ–ª—É—á–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
curl "http://localhost:8002/api/v1/bot/settings?telegram_id=123456789"

# –û–±–Ω–æ–≤–∏—Ç—å –º–æ–¥–µ–ª—å
curl -X PATCH "http://localhost:8002/api/v1/bot/settings?telegram_id=123456789" \
  -H "Content-Type: application/json" \
  -d '{"preferred_ai_model": "claude-sonnet-3.5"}'
```

3. **–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤ –±–æ—Ç–µ:**
- –û—Ç–ø—Ä–∞–≤–∏—Ç—å `/settings`
- –í—ã–±—Ä–∞—Ç—å "ü§ñ –í—ã–±–æ—Ä AI –º–æ–¥–µ–ª–∏"
- –ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å –º–æ–¥–µ–ª—å
- –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–∞–±–æ—Ç—É AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞

---

## üìù –≠—Ç–∞–ø 8: –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π

### 8.1 –î–æ–±–∞–≤–∏—Ç—å –≤ help –±–æ—Ç–∞

```python
@router.message(Command("help"))
async def cmd_help(message: Message):
    help_text = """
ü§ñ <b>–í—ã–±–æ—Ä AI –º–æ–¥–µ–ª–∏</b>

–í—ã –º–æ–∂–µ—Ç–µ –≤—ã–±—Ä–∞—Ç—å –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º—É—é AI –º–æ–¥–µ–ª—å –¥–ª—è:
‚Ä¢ AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
‚Ä¢ –ê–Ω–∞–ª–∏—Ç–∏–∫–∏ –ø—Ä–æ–¥–∞–∂
‚Ä¢ –ì–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞

–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:
‚Ä¢ <b>GPT-4o</b> - –±—ã—Å—Ç—Ä–∞—è –∏ —Ç–æ—á–Ω–∞—è –º–æ–¥–µ–ª—å –æ—Ç OpenAI
‚Ä¢ <b>Claude Sonnet 3.5</b> - –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –º–æ–¥–µ–ª—å –æ—Ç Anthropic

–î–ª—è –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ /settings ‚Üí –í—ã–±–æ—Ä AI –º–æ–¥–µ–ª–∏
    """
    await message.answer(help_text)
```

---

## üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –º–µ—Ç—Ä–∏–∫–∏

### 9.1 –î–æ–±–∞–≤–∏—Ç—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

```python
import logging

logger = logging.getLogger(__name__)

async def send_message(self, telegram_id: int, message: str):
    user_model = await self.get_user_model(telegram_id)
    
    logger.info(
        f"AI Chat request: user={telegram_id}, model={user_model}, "
        f"message_length={len(message)}"
    )
    
    # ... –æ—Å—Ç–∞–ª—å–Ω–æ–π –∫–æ–¥ ...
```

### 9.2 –ú–µ—Ç—Ä–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π

```sql
-- –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π
SELECT 
    preferred_ai_model,
    COUNT(*) as users_count,
    ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER(), 2) as percentage
FROM users
GROUP BY preferred_ai_model
ORDER BY users_count DESC;
```

---

## ‚úÖ –ß–µ–∫–ª–∏—Å—Ç —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

- [ ] –°–æ–∑–¥–∞—Ç—å –º–∏–≥—Ä–∞—Ü–∏—é –ë–î
- [ ] –û–±–Ω–æ–≤–∏—Ç—å –º–æ–¥–µ–ª—å User
- [ ] –°–æ–∑–¥–∞—Ç—å enum AIModel
- [ ] –î–æ–±–∞–≤–∏—Ç—å API endpoints
- [ ] –û–±–Ω–æ–≤–∏—Ç—å –∫–ª–∞–≤–∏–∞—Ç—É—Ä—ã –±–æ—Ç–∞
- [ ] –°–æ–∑–¥–∞—Ç—å handler –Ω–∞—Å—Ç—Ä–æ–µ–∫
- [ ] –û–±–Ω–æ–≤–∏—Ç—å API –∫–ª–∏–µ–Ω—Ç –±–æ—Ç–∞
- [ ] –°–æ–∑–¥–∞—Ç—å UniversalLLMClient
- [ ] –û–±–Ω–æ–≤–∏—Ç—å AI Chat —Å–µ—Ä–≤–∏—Å
- [ ] –û–±–Ω–æ–≤–∏—Ç—å Analysis —Å–µ—Ä–≤–∏—Å
- [ ] –û–±–Ω–æ–≤–∏—Ç—å .env —Ñ–∞–π–ª—ã
- [ ] –ù–∞–ø–∏—Å–∞—Ç—å —Ç–µ—Å—Ç—ã
- [ ] –û–±–Ω–æ–≤–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é
- [ ] –ü—Ä–æ–≤–µ—Å—Ç–∏ —Ä—É—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
- [ ] –ó–∞–¥–µ–ø–ª–æ–∏—Ç—å –Ω–∞ production

---

## üéØ –†–µ–∑—É–ª—å—Ç–∞—Ç

–ü–æ—Å–ª–µ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:
1. –ö–∞–∂–¥—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –º–æ–∂–µ—Ç –≤—ã–±—Ä–∞—Ç—å —Å–≤–æ—é AI –º–æ–¥–µ–ª—å
2. –í—ã–±–æ—Ä —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤ –ë–î
3. –ú–æ–¥–µ–ª—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –≤—Å–µ—Ö AI —Ñ—É–Ω–∫—Ü–∏–π
4. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è GPT-4o
5. –õ–µ–≥–∫–æ –¥–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –≤ –±—É–¥—É—â–µ–º

**–°—Ç–∞—Ç—É—Å:** üìù –ì–æ—Ç–æ–≤–æ –∫ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
